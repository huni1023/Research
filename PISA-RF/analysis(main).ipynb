{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 학업탄력성 영향요인 연구\n",
    "@author: sjh\n",
    "\n",
    "- 전체 데이터 로드 및 가공\n",
    "\n",
    "## 1. Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Current OS:  win32\n",
      ">> Current WD:  c:\\Users\\jhun1\\Dev\\Research\\MixedRF\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import copy\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# unicode minus를 사용하지 않기 위한 설정 (minus 깨짐현상 방지)\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "plt.rcParams[\"figure.autolayout\"] = True\n",
    "\n",
    "# 설치된 폰트 출력\n",
    "import matplotlib.font_manager as fm\n",
    "font_list = [font.name for font in fm.fontManager.ttflist]\n",
    "plt.rcParams['font.family'] = 'Malgun Gothic'\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set_style(\"darkgrid\")\n",
    "\n",
    "\n",
    "App_dir = os.getcwd()\n",
    "Data_dir = os.path.join(App_dir, 'data')\n",
    "Result_dir = os.path.join(App_dir, 'rs')\n",
    "print('>> Current WD: ', App_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Preprocessing\n",
    "- 앞선 처리 데이터 불러오기\n",
    "- Load.py로 처리함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loadedData = {'SK': [\n",
    "#             pd.read_excel(os.path.join(BASE_DIR,'data', 'cleanedData(SK).xlsx'), sheet_name='stu'),\n",
    "#             pd.read_excel(os.path.join(BASE_DIR,'data', 'cleanedData(SK).xlsx'), sheet_name='sch'),\n",
    "#             pd.read_excel(os.path.join(BASE_DIR,'data', 'cleanedData(SK).xlsx'), sheet_name='tch'),\n",
    "            \n",
    "#             ],\n",
    "#         'US': [\n",
    "#             pd.read_excel(os.path.join(BASE_DIR,'data', 'cleanedData(US).xlsx'), sheet_name='stu'),\n",
    "#             pd.read_excel(os.path.join(BASE_DIR,'data', 'cleanedData(US).xlsx'), sheet_name='sch'),\n",
    "#             pd.read_excel(os.path.join(BASE_DIR,'data', 'cleanedData(US).xlsx'), sheet_name='tch'),\n",
    "#             ]}\n",
    "with open(os.path.join(App_dir, 'data', 'cleaned.pkl'), 'rb') as f:\n",
    "    loadedData = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class Preprocessing:\n",
    "    # def __init__(self, LoadedData, codeBook, dummyCodeBook, PV_var):\n",
    "\n",
    "class Preprocessing:\n",
    "    def __init__(self, LoadedData, codeBook, PV_var):\n",
    "        self.data = LoadedData\n",
    "        BASE_DIR = r'C:\\Users\\jhun1\\Dropbox\\[2]Project\\[혼합효과 랜덤포레스트_2022]' #!#\n",
    "        self.cb = pd.read_excel(os.path.join(BASE_DIR, 'drive-download-20220816T053902Z-001', codeBook), sheet_name='변수선택(1213)')\n",
    "        self.PV_var = PV_var\n",
    "\n",
    "        #!# testBook 기능 확인 필요함, 이전 파일 참고\n",
    "        self.testBook = {\n",
    "                    'read/math/sci_1': 'PV1MATH PV1READ PV1SCIE'.split(),\n",
    "                    'read/math_1': 'PV1MATH PV1READ'.split(),\n",
    "                    'read/math_10': 'PV1MATH PV2MATH PV3MATH PV4MATH PV5MATH PV6MATH PV7MATH PV8MATH PV9MATH PV10MATH PV1READ PV2READ PV3READ PV4READ PV5READ PV6READ PV7READ PV8READ PV9READ PV10READ'.split(),\n",
    "                    'read_1': ['PV1READ'],\n",
    "                    'read_10': 'PV1READ PV2READ PV3READ PV4READ PV5READ PV6READ PV7READ PV8READ PV9READ PV10READ'.split()\n",
    "                }\n",
    "        self.nation_real_name = {'SK': '대한민국', 'US': '미국'} \n",
    "\n",
    "        self.valid_data = {}\n",
    "        self._2_joined = {}\n",
    "        self._3_dropNa = {}\n",
    "        self._4_ESCS = {'full': {}, 'sliced': {}} # 여기서 데이터 갈라야함\n",
    "        self._5_shouldBeCal = {}\n",
    "        self.finalRS = {}\n",
    "        \n",
    "        self.rs_deescriptive_Full = pd.DataFrame()\n",
    "        self.rs_deescriptive_SK = pd.DataFrame()\n",
    "        self.rs_deescriptive_US = pd.DataFrame()\n",
    "        \n",
    "\n",
    "    ### Needs1. is selected variable contained in both dataset\n",
    "    #!# load.py의 함수와 병합하기\n",
    "    def noDataColumn(self):\n",
    "        r\"\"\"\n",
    "        - drop feature, if it has too many NA (over 80%) \n",
    "        \"\"\"\n",
    "        toDrop = {}\n",
    "        \n",
    "        for nationName, nationalData in self.data.items():\n",
    "            toDrop[nationName] = []\n",
    "            for idx, (label, inputDf) in enumerate(zip('stu sch tch'.split(), nationalData)):\n",
    "                if label == 'tch': #!# 굳이 tch을 살펴보지 않은 이유는?\n",
    "                    pass\n",
    "                else:\n",
    "                    for column in inputDf.columns:\n",
    "                        if inputDf[column].isna().sum() > (inputDf.shape[0] * 0.8):\n",
    "                            print('>>> too much NA: ', column)\n",
    "                            toDrop[nationName].append(column)\n",
    "                            continue\n",
    "                        \n",
    "                        elif 'missing' in inputDf[column].values:\n",
    "                            print('>>> missing: ', column)\n",
    "                            toDrop[nationName].append(column)\n",
    "                            continue\n",
    "                        \n",
    "                        else:\n",
    "                            continue\n",
    "\n",
    "            for nation, grouped_data in self.data.items():\n",
    "                self.valid_data[nation] = []\n",
    "                for idx, each_group_data in enumerate(grouped_data):\n",
    "                    if idx == 0 : # in case of 'student'\n",
    "                        #!# 코드북고 함께 확인필요, 굳이 RESPECT열을 떨군 이유가?\n",
    "                        self.valid_data[nation].append(each_group_data.drop('PERSPECT', axis=1))\n",
    "                    else: \n",
    "                        self.valid_data[nation].append(each_group_data)\n",
    "                        \n",
    "        return toDrop\n",
    "\n",
    "\n",
    "    def Join(self):\n",
    "        r\"\"\"\n",
    "        join student and school dataframe\n",
    "        #!# 교사데이터는 어디서 합치는가\n",
    "        \"\"\"\n",
    "        print('\\n\\n>>>> 2. Join DataFrame')\n",
    "\n",
    "        for nationalName, inputNational in self.valid_data.items():\n",
    "            # print('>> join nation: ', nationalName)\n",
    "            df_student = inputNational[0].copy()\n",
    "            df_school = inputNational[1].copy()\n",
    "            \n",
    "            df_student.reset_index(drop=True, inplace=True)\n",
    "            \n",
    "            rs = copy.deepcopy(df_student)\n",
    "            before = df_student.shape\n",
    "\n",
    "\n",
    "            df_school.drop(['CNTRYID', 'CNT'], axis=1, inplace=True)\n",
    "            if df_school.index.name != 'CNTSCHID':\n",
    "                df_school.set_index('CNTSCHID', drop=True, inplace=True)\n",
    "            \n",
    "            if df_school.shape[1] == 0:\n",
    "                print('>> school data is empty')\n",
    "                pass\n",
    "            else:\n",
    "                for idx in tqdm(df_student.index, desc=\">> mapping\"):\n",
    "                    toBeInput = df_school.loc[idx, 'CNTSCHID'].values # 학생 데이터에 들어가야할 학교 데이터 찾기\n",
    "                    assert len(toBeInput) == df_school.shape[1]\n",
    "                    \n",
    "                    toBeInput_T = toBeInput.reshape(1, 8)\n",
    "                    rs.loc[idx, list(df_school.columns)] = toBeInput_T[0]\n",
    "            \n",
    "                after = rs.shape\n",
    "                print('>>>> Bef: ', before, '....', 'Aft: ', after)\n",
    "                assert 'EDUSHORT' in rs.columns #!# 왜 필요할까\n",
    "\n",
    "            self._2_joined[nationalName] = rs\n",
    "        return rs\n",
    "\n",
    "    def DropStudent(self, na_threshold: int, is_visualize=True):\n",
    "        r\"\"\"\n",
    "        drop student who have too many NA value\n",
    "        Parameters\n",
    "        ----------\n",
    "        na_threshold: int\n",
    "            drop student who have NA value above this threshold\n",
    "        \"\"\"\n",
    "        print('\\n>>>> 3. Verify na and Drop student')\n",
    "        def column_wise_NA(inputData) -> dict:\n",
    "            r\"\"\"generate column-wise NA ratio\"\"\"\n",
    "            if type(inputData) == dict:\n",
    "                merged = pd.concat([inputData['SK'], inputData['US']])\n",
    "                assert merged.shape[0] == inputData['SK'].shape[0] + inputData['US'].shape[0]\n",
    "            \n",
    "            elif type(inputData) == pd.DataFrame:\n",
    "                merged = copy.deepcopy(inputData)\n",
    "            \n",
    "            else:\n",
    "                raise TypeError('dictionary or pd.DataFrame is allowed')\n",
    "                \n",
    "\n",
    "            describeDF = merged.describe().T\n",
    "            describeDF['NA_ratio'] = round(100 - describeDF['count']/merged.shape[0]*100, 2)\n",
    "\n",
    "            newColumnOrder = [describeDF.columns[0], 'NA_ratio'] + list(describeDF.columns[1:-1])\n",
    "            describeDF= describeDF[newColumnOrder]\n",
    "            return describeDF\n",
    "\n",
    "        # 각 학생별로 데이터 검수\n",
    "        def row_wise_NA(inputData: dict, is_visualize: bool, na_threshold: int) -> dict:\n",
    "            r\"\"\"calculate NA ratio per student\"\"\"\n",
    "            merged = pd.concat([inputData['SK'], inputData['US']])\n",
    "            assert merged.shape[0] == inputData['SK'].shape[0] + inputData['US'].shape[0]\n",
    "\n",
    "            for_histogram = {}\n",
    "            rs = {}\n",
    "            for label, data in zip(['full', 'SK', 'US'], [merged, inputData['SK'], inputData['US']]):\n",
    "                for_histogram[label] = []\n",
    "                to_drop = []\n",
    "\n",
    "                for i in range(len(data.index)) :\n",
    "                    na_cnt = data.iloc[i].isnull().sum()\n",
    "                    na_ratio = round((na_cnt/data.shape[1]) * 100, 0)\n",
    "                    for_histogram[label].append(na_ratio)\n",
    "                    if na_cnt > na_threshold:\n",
    "                        to_drop.append(i)\n",
    "                print(f'>> NA drop of {label}: ', len(to_drop))\n",
    "                rs[label] = data.drop(to_drop, axis=1)\n",
    "\n",
    "            if is_visualize == True:\n",
    "                fig = plt.figure(figsize=(17,6))\n",
    "\n",
    "                plt.subplot(1, 3, 1)\n",
    "                plt.hist(for_histogram['full'])\n",
    "                plt.title('\\n전체 데이터\\n')\n",
    "                plt.xlabel('\\n전체 변수 대비 결측비율(%)\\n')\n",
    "                plt.ylabel('빈도')\n",
    "                \n",
    "                plt.subplot(1, 3, 2)\n",
    "                plt.hist(for_histogram['SK'])\n",
    "                plt.title('\\nSouth Korea\\n')\n",
    "                plt.xlabel('\\n전체 변수 대비 결측비율(%)\\n')\n",
    "                plt.ylabel('빈도')\n",
    "                \n",
    "                plt.subplot(1, 3, 3)\n",
    "                plt.hist(for_histogram['US'])\n",
    "                plt.title('\\nUnited States\\n')\n",
    "                plt.xlabel('\\n전체 변수 대비 결측비율(%)\\n')\n",
    "                plt.ylabel('빈도')\n",
    "\n",
    "                plt.savefig(os.path.join(Data_dir, f'NA_ratio.png'))\n",
    "                plt.show()\n",
    "\n",
    "\n",
    "            return rs\n",
    "        \n",
    "        #!# 이 부분은 sequential한 단계에서 빠져야할 것 같음, EDA에 가까움\n",
    "        # visualize와 같이, debug 단계만 사용되면 되고, 나머지에서는 굳이 계산할 필요가 없음\n",
    "        self.rs_deescriptive_Full = column_wise_NA(self._2_joined)\n",
    "        self.rs_deescriptive_SK = column_wise_NA(self._2_joined['SK'])\n",
    "        self.rs_deescriptive_US = column_wise_NA(self._2_joined['US'])\n",
    "\n",
    "        clean_data_using_rowwise_NA = row_wise_NA(self._2_joined, na_threshold=na_threshold, is_visualize=is_visualize)\n",
    "        self._3_dropNa['SK'] = clean_data_using_rowwise_NA['SK']\n",
    "        self._3_dropNa['US'] = clean_data_using_rowwise_NA['US']\n",
    "        return self._3_dropNa\n",
    "        \n",
    "        \n",
    "    def slice_by_ESCS(self, acad_threshold: int, is_visualize=True) -> dict:\n",
    "        r\"\"\"\n",
    "        calculate ESCS variable and devide dataset by full and sliced\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        acad_threshold: int\n",
    "            academic score thrshold\n",
    "        \"\"\"\n",
    "        print('\\n>>>> 4. Slicing data by ESCS')\n",
    "        \n",
    "        def thresholdCalculator(data: dict,\n",
    "                                PV_var: int,\n",
    "                                acad_threshold: int):\n",
    "            r\"\"\"calculate 2 kinds of threshold,\n",
    "            1. academic score\n",
    "            2. ESCS\n",
    "            \"\"\"\n",
    "            assert type(PV_var) == int, 'insert valid PV_var type'\n",
    "            assert type(acad_threshold) == int, 'insert valid threshold type'\n",
    "            assert (PV_var > 0) and (PV_var < 11), print('>> Error__PV_var: ', PV_var)\n",
    "\n",
    "            threshold_dict = {'SK': {'academic_score': acad_threshold}, 'US': {'academic_score': acad_threshold}}\n",
    "            targetColumn = ['PV'+ str(PV_var) + 'READ']\n",
    "            rs = data.copy()\n",
    "\n",
    "            for nationalName, inputNational in data.items():\n",
    "                rs[nationalName]['AcademicScore'] = inputNational.loc[:, targetColumn].mean(axis=1)\n",
    "                threshold_dict[nationalName]['escs_score'] = inputNational['ESCS'].quantile(0.25)\n",
    "\n",
    "            return threshold_dict, rs\n",
    "        \n",
    "        def slice_by_escs(data: dict, escsThreshold: dict) -> dict:\n",
    "            r\"\"\"slice data by escs score\n",
    "            \"\"\"\n",
    "            assert type(data) == dict, 'insert valid data'\n",
    "            assert type(escsThreshold) == dict, 'insert valid threshold'\n",
    "\n",
    "            rs = {'SK': pd.DataFrame(), 'US': pd.DataFrame()}\n",
    "            for nationalName, inputNational in data.items():\n",
    "                before = inputNational.shape[0]\n",
    "                toDrop = []\n",
    "                for idx, val in zip(inputNational['ESCS'].index, inputNational['ESCS'].values):\n",
    "                    if val < escsThreshold[nationalName]['escs_score']:\n",
    "                        continue\n",
    "                    else:\n",
    "                        toDrop.append(idx)\n",
    "                \n",
    "                rs[nationalName] = inputNational.drop(toDrop, axis=0)\n",
    "                after = rs[nationalName].shape[0]\n",
    "                print('>> before: ', before, '>> after: ', after)\n",
    "            \n",
    "            return rs\n",
    "\n",
    "\n",
    "        def labeling_resilient( \n",
    "                            data, # 전체 Full, escs 하위 25%로 데이터셋이 2개로 나뉘므로 인풋을 줘야함\n",
    "                            option: str, # full: 전체 데이터, sliced: 잘린 데이터\n",
    "                            threshold_info: dict\n",
    "                            ):\n",
    "            r\"\"\"\n",
    "            Parameters\n",
    "            ----------\n",
    "            option: str\n",
    "                full or sliced\n",
    "\n",
    "            if condition1: using academic score\n",
    "                & condition2: using escs score\n",
    "                full: condition1 & condition2\n",
    "                sliced: condition1\n",
    "                - since sliced data already sliced by escs score\n",
    "            \"\"\"\n",
    "            if (option == 'full') or (option == 'sliced'): pass\n",
    "            else:\n",
    "                raise ValueError('input valid option args')\n",
    "                \n",
    "            assert type(threshold_info) == dict\n",
    "            rs = {'SK': pd.DataFrame(), 'US': pd.DataFrame()}\n",
    "            \n",
    "            \n",
    "            for nationalName, inputNational in data.items():\n",
    "                threshold_acad = threshold_info[nationalName]['academic_score']\n",
    "                threshold_escs = threshold_info[nationalName]['escs_score']\n",
    "                \n",
    "                iamResilient = []\n",
    "                for idx in inputNational.index:\n",
    "                    val_acad = inputNational.loc[idx, 'AcademicScore']\n",
    "                    val_escs = inputNational.loc[idx, 'ESCS']\n",
    "                    if option == 'full':\n",
    "                        if (val_acad > threshold_acad) and (val_escs < threshold_escs):\n",
    "                            iamResilient.append(1)\n",
    "                        else: iamResilient.append(0)\n",
    "                    elif option == 'sliced': #!# 여기서 에러 날수도..?\n",
    "                        if val_acad > threshold_acad:\n",
    "                            iamResilient.append(1)\n",
    "                        else: iamResilient.append(0)\n",
    "\n",
    "                inputNational['resilient'] = iamResilient\n",
    "                rs[nationalName] = inputNational.copy()\n",
    "\n",
    "            return rs\n",
    "        \n",
    "        def table_resilient_ratio(data: dict) -> list:\n",
    "            r\"\"\"회복탄력성을 지닌 학생의 전체 대비 비율을 계산함\"\"\"\n",
    "            count_ratio = {'SK': [], 'US': []} #!# count, ratio로 dict형태인게 더 나아보임\n",
    "            for nationalName in count_ratio.keys():\n",
    "                total = data[nationalName].shape[0]\n",
    "                is_resilient = data[nationalName]['resilient'].values\n",
    "\n",
    "                resilientCount = [x for x in is_resilient if x == 1]\n",
    "                resilientRatio = round(len(resilientCount)/total * 100, 2)\n",
    "                count_ratio[nationalName].append(len(resilientCount))\n",
    "                count_ratio[nationalName].append(resilientRatio)\n",
    "                print(f'>> 회복탄력성 보유 학생수({nationalName}): ', len(resilientCount), f'({resilientRatio})%')\n",
    "            return count_ratio\n",
    "\n",
    "        def visualize(data: dict, option: str, threshold_info: dict,\n",
    "                    figName: str):\n",
    "            r\"\"\"visualize threshold and ratio of sample distribution\n",
    "            option: str\n",
    "                full or sliced\n",
    "            figName: str\n",
    "                title of figure\n",
    "            \"\"\"\n",
    "            fig = plt.figure(figsize=(17,9))\n",
    "            for IDX, (nationalName, inputNational) in enumerate(data.items()):\n",
    "\n",
    "                plt.subplot(2, 2, 2*IDX+1)\n",
    "                plt.hist(inputNational['AcademicScore'])\n",
    "                plt.title(f'\\n학업성취{self.nation_real_name[nationalName]}\\n')\n",
    "                plt.xlabel('\\n점수\\n')\n",
    "                plt.axvline(threshold_info[nationalName]['academic_score'], color='r', linewidth=1, linestyle='--')\n",
    "                \n",
    "                plt.subplot(2, 2, 2*IDX+2)\n",
    "                plt.hist(inputNational['ESCS'])\n",
    "                plt.title(f'\\n사회문화경제{self.nation_real_name[nationalName]}\\n')\n",
    "                plt.xlabel('\\n점수\\n')\n",
    "                if option=='full':\n",
    "                    plt.axvline(threshold_info[nationalName]['escs_score'], color='r', linewidth=1, linestyle='--')\n",
    "\n",
    "                \n",
    "            plt.savefig(os.path.join(Result_dir, f'{figName}_{option}.png'))\n",
    "            plt.show()\n",
    "        \n",
    "        ## 1. calculate threshold value: 따로 메소드로 빼도 될듯\n",
    "        threshold_info, newData_dict = thresholdCalculator(self._3_dropNa,\n",
    "                                                            PV_var = self.PV_var,\n",
    "                                                            acad_threshold = acad_threshold) ##!#!## 학업성취 코딩 방법을 바꿀 때 여기 arg를 조정\n",
    "        \n",
    "        \n",
    "        ## 2. slice\n",
    "        self._4_ESCS['full'] = copy.deepcopy(newData_dict) # no drop case, so just copied\n",
    "        self._4_ESCS['sliced'] = slice_by_escs(newData_dict, escsThreshold = threshold_info)\n",
    "        assert type(self._4_ESCS['full']) == dict, print(self._4_ESCS['full'])\n",
    "\n",
    "\n",
    "        ## 3. labeling resilient student\n",
    "        self._4_ESCS['full'] = labeling_resilient(inputData=self._4_ESCS['full'], \n",
    "                                                option = 'full',\n",
    "                                                AcademicThreshold= threshold_info)\n",
    "        self._4_ESCS['sliced'] = labeling_resilient(inputData=self._4_ESCS['sliced'], \n",
    "                                                option = 'sliced',\n",
    "                                                AcademicThreshold= threshold_info)\n",
    "        \n",
    "        #!# 앞선 visualize 단계와 마찬가지임, debug단계가 아니면 확인하지 않는 부분임\n",
    "        resilientCount_Ratio_full = table_resilient_ratio(data=self._4_ESCS['full'])\n",
    "        resilientCount_Ratio = table_resilient_ratio(data=self._4_ESCS['sliced'])\n",
    "\n",
    "        ## 4. visualize resilient student\n",
    "        if is_visualize == True:\n",
    "            visualize(self._4_ESCS['full'], option='full', figName='읽10', threshold_info= threshold_info)\n",
    "            visualize(self._4_ESCS['sliced'], option = 'sliced', figName ='읽10(target paper)', threshold_info= threshold_info)\n",
    "        \n",
    "        return resilientCount_Ratio\n",
    "\n",
    "    \n",
    "    # should be calculated 변수들 계산하는 것임\n",
    "    def shouldBeCalculated(self):\n",
    "        # print('\\n\\n>>>> 6. Should Be Calculated')\n",
    "        \n",
    "        def schoolMean(inputDf, whichVar):\n",
    "            assert type(whichVar) == list\n",
    "            outputMean = {}\n",
    "            for sch_id in inputDf['CNTSCHID'].values:\n",
    "                if sch_id in outputMean.keys():\n",
    "                    continue\n",
    "                \n",
    "                else:\n",
    "                    temp1 = inputDf[inputDf['CNTSCHID'] == sch_id]\n",
    "                    temp2 = temp1.loc[:, whichVar] \n",
    "                    assert len(temp2.columns) == len(whichVar)\n",
    "                    meanVal = np.nanmean(temp2.values)\n",
    "                    assert type(meanVal) == np.float64, print('Error : ', type(meanVal))\n",
    "\n",
    "                    outputMean[sch_id] = meanVal\n",
    "            \n",
    "            return outputMean\n",
    "        \n",
    "        \n",
    "        def meanMapping(inputColumn, mean_dict):\n",
    "            outputLS = []\n",
    "            for idx, sch_id in enumerate(inputColumn.values):\n",
    "                outputLS.append(mean_dict[sch_id])\n",
    "\n",
    "            return outputLS\n",
    "        \n",
    "\n",
    "        def matching(inputData, codeBook):\n",
    "            output = copy.deepcopy(inputData)\n",
    "            shouldBeCal = self.cb[self.cb['file name'] == 'should be caculated']\n",
    "            assert len(shouldBeCal) == 2, print('Error: check self.cb')\n",
    "            for national in output.keys():\n",
    "                beforeShape = output[national].shape[1]\n",
    "                \n",
    "                calVal = list(codeBook[codeBook['categories'] == 'resilient status']['NAME'])\n",
    "                calVal.remove('ESCS')\n",
    "                \n",
    "                for variable in shouldBeCal['NAME'].values:\n",
    "                \n",
    "                    if variable == 'AVG_S_TEST':    \n",
    "                        mean_dict = schoolMean(output[national], calVal)\n",
    "                        \n",
    "                    elif variable == 'AVG_S_ESCS':\n",
    "                        mean_dict = schoolMean(output[national], ['ESCS'])\n",
    "\n",
    "                    #평균 dict 활용해서 매칭 진행\n",
    "                    outputLS = meanMapping(output[national]['CNTSCHID'], mean_dict)\n",
    "                    assert len(outputLS) == output[national].shape[0], print('Error: ', len(outputLS))\n",
    "                    output[national][variable] = outputLS # 학교 데이터이므로, 학교에 맞춰서 추가하기\n",
    "\n",
    "                afterShape = output[national].shape[1]\n",
    "                assert afterShape - beforeShape == 2, print('Beofre: ', beforeShape, ' ... ', 'After: ', afterShape)\n",
    "            \n",
    "            return output\n",
    "        \n",
    "        if 'should be calculated' in self.cb['file name'].values:\n",
    "            self._5_shouldBeCal['full'] = matching(self._4_ESCS['full'], codeBook = self.cb)\n",
    "            self._5_shouldBeCal['sliced'] = matching(self._4_ESCS['sliced'], codeBook = self.cb)\n",
    "        else:\n",
    "            self._5_shouldBeCal['full'] = copy.deepcopy(self._4_ESCS['full'])\n",
    "            self._5_shouldBeCal['sliced'] = copy.deepcopy(self._4_ESCS['sliced'])\n",
    "            \n",
    "\n",
    "    \n",
    "    def AdjustMinor(self):\n",
    "        r\"\"\"마이너한 것들을 조정하기 위함\"\"\"\n",
    "        \n",
    "        def Merge(inputData):\n",
    "            r\"\"\"두 데이터를 나라 row를 만들고, 합치기 위함\"\"\"\n",
    "            output = pd.concat([inputData['SK'], inputData['US']], axis=0)\n",
    "            assert inputData['SK'].shape[0] + inputData['US'].shape[0] == output.shape[0]\n",
    "\n",
    "            dropAcademic = ['CNTRYID', 'AcademicScore']\n",
    "            for column in output.columns:\n",
    "                if 'PV' in column:\n",
    "                    dropAcademic.append(column)\n",
    "\n",
    "            output.drop(dropAcademic, axis=1, inplace=True)\n",
    "            # print('>> columns: ', output.columns)\n",
    "            return output\n",
    "\n",
    "        def columnOrder(inputData,\n",
    "                        important_columns=['resilient']):\n",
    "            r\"\"\"spss 편하도록, 주요 변수들을 앞으로 빼는 작업\"\"\"\n",
    "            column_ID = ['CNT', 'CNTSCHID', 'CNTSTUID']\n",
    "\n",
    "            inputData.set_index(column_ID+important_columns, inplace=True)\n",
    "            inputData.reset_index(inplace=True)\n",
    "\n",
    "            return inputData\n",
    "\n",
    "        self.finalRS['full'] = Merge(self._5_shouldBeCal['full'])\n",
    "        self.finalRS['sliced'] = Merge(self._5_shouldBeCal['sliced'])\n",
    "\n",
    "        self.finalRS['full'] = columnOrder(self.finalRS['full'])\n",
    "        self.finalRS['sliced'] = columnOrder(self.finalRS['sliced'])\n",
    "\n",
    "    def Save(self):\n",
    "        with pd.ExcelWriter(os.path.join(Result_dir, f'preprocessing{self.PV_var}.xlsx')) as writer:\n",
    "            self.finalRS['sliced'].to_excel(writer, sheet_name='sliced', index=False)\n",
    "\n",
    "\n",
    "# processor = Preprocessing(LoadedData=loadedData, codeBook=Loader.cb, PV_var=1)\n",
    "# processor.noDataColumn()\n",
    "# processor.Join()\n",
    "# processor.DropStudent(na_threshold=30, is_visualize=False)\n",
    "# processor.slice_by_ESCS(480, is_visualize=False) # Lv4: 553, Lv3: 480, Lv2: 407\n",
    "# processor.shouldBeCalculated()\n",
    "# processor.AdjustMinor()\n",
    "# processor.Save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>>  1\n",
      "\n",
      ">>>> 4. Slicing data by ESCS\n",
      ">  {'SK': [876, 52.96], 'US': [483, 41.14]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 1/10 [00:04<00:41,  4.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>>  2\n",
      "\n",
      ">>>> 4. Slicing data by ESCS\n",
      ">  {'SK': [857, 51.81], 'US': [475, 40.46]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 2/10 [00:09<00:36,  4.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>>  3\n",
      "\n",
      ">>>> 4. Slicing data by ESCS\n",
      ">  {'SK': [863, 52.18], 'US': [473, 40.29]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 3/10 [00:13<00:31,  4.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>>  4\n",
      "\n",
      ">>>> 4. Slicing data by ESCS\n",
      ">  {'SK': [855, 51.69], 'US': [487, 41.48]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 4/10 [00:18<00:26,  4.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>>  5\n",
      "\n",
      ">>>> 4. Slicing data by ESCS\n",
      ">  {'SK': [852, 51.51], 'US': [474, 40.37]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 5/10 [00:22<00:22,  4.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>>  6\n",
      "\n",
      ">>>> 4. Slicing data by ESCS\n",
      ">  {'SK': [838, 50.67], 'US': [484, 41.23]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 6/10 [00:27<00:17,  4.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>>  7\n",
      "\n",
      ">>>> 4. Slicing data by ESCS\n",
      ">  {'SK': [858, 51.87], 'US': [477, 40.63]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 7/10 [00:31<00:13,  4.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>>  8\n",
      "\n",
      ">>>> 4. Slicing data by ESCS\n",
      ">  {'SK': [847, 51.21], 'US': [463, 39.44]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 8/10 [00:35<00:08,  4.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>>  9\n",
      "\n",
      ">>>> 4. Slicing data by ESCS\n",
      ">  {'SK': [859, 51.93], 'US': [485, 41.31]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 9/10 [00:40<00:04,  4.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>>  10\n",
      "\n",
      ">>>> 4. Slicing data by ESCS\n",
      ">  {'SK': [866, 52.36], 'US': [475, 40.46]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:44<00:00,  4.45s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>876</td>\n",
       "      <td>52.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>857</td>\n",
       "      <td>51.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>863</td>\n",
       "      <td>52.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>855</td>\n",
       "      <td>51.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>852</td>\n",
       "      <td>51.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>838</td>\n",
       "      <td>50.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>858</td>\n",
       "      <td>51.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>847</td>\n",
       "      <td>51.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>859</td>\n",
       "      <td>51.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>866</td>\n",
       "      <td>52.36</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   count  ratio\n",
       "1    876  52.96\n",
       "2    857  51.81\n",
       "3    863  52.18\n",
       "4    855  51.69\n",
       "5    852  51.51\n",
       "6    838  50.67\n",
       "7    858  51.87\n",
       "8    847  51.21\n",
       "9    859  51.93\n",
       "10   866  52.36"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#!# 이거 자체를 하나의 fnc으로 빼야함\n",
    "\n",
    "plot_sk = pd.DataFrame(index=range(1, 11), columns=['count', 'ratio'])\n",
    "plot_us = pd.DataFrame(index=range(1, 11), columns=['count', 'ratio'])\n",
    "\n",
    "for idx in tqdm(range(1, 11)):\n",
    "    print('>>>> ', idx)\n",
    "    processor = Preprocessing(LoadedData=loadedData, codeBook='PISA2018_CODEBOOK (변수선택-공유).xlsx', PV_var=idx)\n",
    "    processor.noDataColumn()\n",
    "    processor.Join()\n",
    "    processor.DropStudent(na_threshold=30, is_visualize=False)\n",
    "    processor.slice_by_ESCS(480, is_visualize=False) # Lv4: 553, Lv3: 480, Lv2: 407\n",
    "    \n",
    "    processor.shouldBeCalculated()\n",
    "    processor.AdjustMinor()\n",
    "    processor.Save()\n",
    "\n",
    "    plot_sk.loc[idx, 'count'] = resilientCount_Ratio['SK'][0]\n",
    "    plot_sk.loc[idx, 'ratio'] = resilientCount_Ratio['SK'][1]\n",
    "    plot_us.loc[idx, 'count'] = resilientCount_Ratio['US'][0]\n",
    "    plot_us.loc[idx, 'ratio'] = resilientCount_Ratio['US'][1]\n",
    "\n",
    "\n",
    "display(plot_sk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>483</td>\n",
       "      <td>41.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>475</td>\n",
       "      <td>40.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>473</td>\n",
       "      <td>40.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>487</td>\n",
       "      <td>41.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>474</td>\n",
       "      <td>40.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>484</td>\n",
       "      <td>41.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>477</td>\n",
       "      <td>40.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>463</td>\n",
       "      <td>39.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>485</td>\n",
       "      <td>41.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>475</td>\n",
       "      <td>40.46</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   count  ratio\n",
       "1    483  41.14\n",
       "2    475  40.46\n",
       "3    473  40.29\n",
       "4    487  41.48\n",
       "5    474  40.37\n",
       "6    484  41.23\n",
       "7    477  40.63\n",
       "8    463  39.44\n",
       "9    485  41.31\n",
       "10   475  40.46"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(plot_us)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plt.bar\n",
    "should be plotted"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('khrrc')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f2ed4711497f95c801e11ec0b21dd929a4a0de8689951f49fbf9abba32131afd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
