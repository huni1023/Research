{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/huni/.pyenv/versions/3.8.2/envs/{huni}/lib/python3.8/site-packages/pandas/compat/__init__.py:97: UserWarning: Could not import the lzma module. Your installed Python is incomplete. Attempting to use lzma compression will result in a RuntimeError.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Current OS:  darwin\n",
      ">> Current WD:  /Users/huni/Proj/Research/MixedRF\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import copy\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "from sys import platform\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# unicode minus를 사용하지 않기 위한 설정 (minus 깨짐현상 방지)\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "plt.rcParams[\"figure.autolayout\"] = True\n",
    "\n",
    "# 설치된 폰트 출력\n",
    "import matplotlib.font_manager as fm\n",
    "font_list = [font.name for font in fm.fontManager.ttflist]\n",
    "plt.rcParams['font.family'] = 'Malgun Gothic'\n",
    "\n",
    "\n",
    "BASE_DIR = os.getcwd()\n",
    "print('>> Current OS: ', platform)\n",
    "print('>> Current WD: ', BASE_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>>> Init: load raw data\n",
      ">> Stu data set (6037, 1119)\n",
      ">> Sch data set (152, 197)\n",
      ">> Tch data set (3754, 351)\n"
     ]
    }
   ],
   "source": [
    "class Load:\n",
    "    def __init__(self, codeBook):\n",
    "        if 'darwin' in platform:\n",
    "            self.BASE_DIR = '/Users/huni/Dropbox/[3]Project/[혼합효과 랜덤포레스트_2022]'\n",
    "        else:\n",
    "            self.BASE_DIR = r'C:\\Users\\jhun1\\Dropbox\\[3]Project\\[혼합효과 랜덤포레스트_2022]'\n",
    "        \n",
    "        global BASE_DIR\n",
    "        codebook_Folder = 'drive-download-20220816T053902Z-001'\n",
    "\n",
    "        print('>>>>> Init: load raw data')\n",
    "        self.rawStu = pd.read_excel(os.path.join(BASE_DIR, 'data', 'rawData(HK).xlsx'), sheet_name='stu')\n",
    "        self.rawSCH = pd.read_excel(os.path.join(BASE_DIR, 'data', 'rawData(HK).xlsx'), sheet_name='sch')\n",
    "        self.rawTCH = pd.read_excel(os.path.join(BASE_DIR, 'data', 'rawData(HK).xlsx'), sheet_name='tch')\n",
    "        self.dataLS = [self.rawStu, self.rawSCH, self.rawTCH]\n",
    "\n",
    "        # desciptive\n",
    "        print('>> Stu data set', self.rawStu.shape)\n",
    "        print('>> Sch data set', self.rawSCH.shape)\n",
    "        print('>> Tch data set', self.rawTCH.shape)\n",
    "        \n",
    "        \n",
    "        self.cb = pd.read_excel(os.path.join(self.BASE_DIR, codebook_Folder, codeBook),\n",
    "                            skiprows=[0] # 맨 윗줄 제거\n",
    "                            )\n",
    "\n",
    "\n",
    "Loader = Load(codeBook='TargetPaper_CODEBOOK.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      ">>>> Calculate: academic score and its threshold\n",
      "> Threshold: academic score,  594.5394\n",
      "\n",
      "\n",
      ">>>> Cleaning: select variable\n",
      ">>>> 1. left only identified variable 30\n",
      "> academic_score variable should be left\n",
      "> cleaned : 29\n",
      "\n",
      ">>>> 2. drop useless variable\n",
      "> Stu data only left.. :  30\n",
      "> Sch data only left.. :  0\n",
      "> Tch data only left.. :  0\n",
      "\n",
      "\n",
      ">>>> Slice: slice by escs\n",
      ">> before:  6037 >> after:  1459\n",
      "> resilient students:  242 (16.6%)\n",
      "> not resilient students:  1217 (83.4%)\n"
     ]
    }
   ],
   "source": [
    "class Preprocessing(Load):\n",
    "    def __init__(self, dataLS, cb):\n",
    "        # super().__init__(dataLS, codebook = cb)\n",
    "        self.dataLS = copy.deepcopy(dataLS) # if you not copy, object 'Loader' is damaged\n",
    "        self.cb = cb\n",
    "        self.testBook = {\n",
    "            'read/math/sci_1': 'PV1MATH PV1READ PV1SCIE'.split(),\n",
    "            'read/math_1': 'PV1MATH PV1READ'.split(),\n",
    "            'read/math_10': 'PV1MATH PV2MATH PV3MATH PV4MATH PV5MATH PV6MATH PV7MATH PV8MATH PV9MATH PV10MATH PV1READ PV2READ PV3READ PV4READ PV5READ PV6READ PV7READ PV8READ PV9READ PV10READ'.split(),\n",
    "            'read_1': ['PV1READ'],\n",
    "            'read_10': 'PV1READ PV2READ PV3READ PV4READ PV5READ PV6READ PV7READ PV8READ PV9READ PV10READ'.split()\n",
    "        }\n",
    "        self.threshold = {'academic': None, 'escs': None}\n",
    "\n",
    "    def calculate_academic_score(self, testKey):\n",
    "        ### calculate academic score and mapping whether resilient or not\n",
    "        print('\\n\\n>>>> Calculate: academic score and its threshold')\n",
    "        before = self.dataLS[0].shape[1]\n",
    "        \n",
    "        self.dataLS[0]['academic_score'] = self.dataLS[0].loc[:, self.testBook[testKey]].mean(axis=1)\n",
    "\n",
    "\n",
    "        def threshold(col_academic): # escs 는 계산할 필요 없음\n",
    "            thres_val = col_academic.quantile(0.75) # 반드시 escs 자르기 전에 계산해야 함\n",
    "            return thres_val\n",
    "        \n",
    "        threshold_academic = threshold(self.dataLS[0]['academic_score'])\n",
    "        print('> Threshold: academic score, ', threshold_academic)\n",
    "\n",
    "        self.threshold['academic'] = threshold_academic\n",
    "        after = self.dataLS[0].shape[1]\n",
    "        assert after - before == 1\n",
    "        return None\n",
    "\n",
    "\n",
    "    def defaultCleaner(self):\n",
    "        print('\\n\\n>>>> Cleaning: select variable')\n",
    "\n",
    "        ### slicing only codebook independent var (with academic score)\n",
    "        def drop_Unidentified_variable(codebook):\n",
    "            variable_name = list(codebook['variable_name'].values)\n",
    "            print('>>>> 1. left only identified variable', len(variable_name))\n",
    "            print('> academic_score variable should be left')\n",
    "            new = [variable for variable in variable_name if variable != '?']\n",
    "            new.append('academic_score') # Imp\n",
    "            \n",
    "            print('> cleaned :', len(new))\n",
    "            return new\n",
    "\n",
    "\n",
    "        def cleaningVariable(dataLS, using_variable_list):\n",
    "            print('\\n>>>> 2. drop useless variable')\n",
    "\n",
    "            \"\"\"\n",
    "            1. iteration through data set (stu, sch, tch)\n",
    "            2. iteration through every column\n",
    "            3. save column when it is contained\n",
    "            \"\"\"\n",
    "            new_data_ls = {'Stu': [], 'Sch': [], 'Tch': []}\n",
    "\n",
    "            count = 0\n",
    "            for data_set, label in zip(dataLS, new_data_ls.keys()):\n",
    "                toDrop = []\n",
    "                for col in data_set.columns:\n",
    "                    if col in using_variable_list:\n",
    "                        count += 1\n",
    "                    \n",
    "                    elif col == 'ESCS':\n",
    "                        continue\n",
    "\n",
    "                    else:\n",
    "                        toDrop.append(col)\n",
    "                \n",
    "                newDF = data_set.drop(toDrop, axis=1)\n",
    "                new_data_ls[label] = newDF\n",
    "                print(f'> {label} data only left.. : ', len(newDF.columns))\n",
    "\n",
    "\n",
    "            assert count == len(using_variable_list), print('*error: ', count, \"...\", len(using_variable_list))\n",
    "            \n",
    "            return new_data_ls\n",
    "\n",
    "\n",
    "        var_ls =  drop_Unidentified_variable(self.cb) # cleaening unidentified variable\n",
    "        output = cleaningVariable(dataLS = self.dataLS, using_variable_list=var_ls)\n",
    "        self.cleaned = output['Stu']\n",
    "        assert type(self.cleaned) == pd.DataFrame\n",
    "\n",
    "        return None\n",
    "\n",
    "\n",
    "    def slice(self):\n",
    "        print('\\n\\n>>>> Slice: slice by escs')\n",
    "        self.threshold['escs'] = self.cleaned['ESCS'].quantile(0.25)\n",
    "        df = copy.deepcopy(self.cleaned)\n",
    "        before = df.shape[0]\n",
    "\n",
    "        toDrop = []\n",
    "        for idx, val in zip(df.index, df['ESCS'].values):\n",
    "            if val < self.threshold['escs']:\n",
    "                continue\n",
    "            else:\n",
    "                toDrop.append(idx)\n",
    "\n",
    "        output = df.drop(toDrop, axis = 0)\n",
    "        after = output.shape[0]\n",
    "        print('>> before: ', before, '>> after: ', after)\n",
    "        self.sliced = output\n",
    "        return output\n",
    "    \n",
    "    def coding_resilient(self):\n",
    "        df = copy.deepcopy(self.sliced)\n",
    "        df.reset_index(drop=True, inplace=True) # in case of error, clear index\n",
    "        \n",
    "        for idx, val in enumerate(df['academic_score']):\n",
    "            if val >= self.threshold['academic']:\n",
    "                df.loc[idx, 'resilient'] = 1\n",
    "            else:\n",
    "                df.loc[idx, 'resilient'] = 0\n",
    "\n",
    "        total = df.shape[0]\n",
    "        count_resilient = df[df['resilient']==1].shape[0]\n",
    "        count_not_resilient = df[df['resilient']==0].shape[0]\n",
    "\n",
    "        def percentage(inputC, totalC):\n",
    "            return np.round((inputC/totalC)*100, 1)\n",
    "        print('> resilient students: ', count_resilient, f'({percentage(count_resilient, total)}%)')\n",
    "        print('> not resilient students: ', count_not_resilient, f'({percentage(count_not_resilient, total)}%)')\n",
    "\n",
    "\n",
    "        df.drop(['academic_score'], axis=1, inplace=True) # after calculating is done, drop score column\n",
    "        return df\n",
    "\n",
    "    \n",
    "preprocessor = Preprocessing(dataLS = Loader.dataLS, cb = Loader.cb)\n",
    "preprocessor.calculate_academic_score('read_10') # should be calculated before drop\n",
    "preprocessor.defaultCleaner()\n",
    "df_sliced = preprocessor.slice()\n",
    "df = preprocessor.coding_resilient()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def minor_adjust(inputDf, highlight_column):\n",
    "    assert type(highlight_column) == str, print('> this code only work for adjusting only one column')\n",
    "    \n",
    "    output = copy.deepcopy(inputDf)\n",
    "    output.set_index(highlight_column, drop=True, inplace=True)\n",
    "    output.reset_index(drop=False, inplace=True)\n",
    "    return output\n",
    "\n",
    "cleaned_df = minor_adjust(df, 'resilient')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_df.to_excel(os.path.join(BASE_DIR, 'data', 'cleanedData(HK).xlsx'),\n",
    "            index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SPSS 26.0의 MCMC 사용해서 결측치 대체함 \n",
    "# https://www.statisticshowto.com/missing-values-spss/\n",
    "\n",
    "\n",
    "# reading achivement top 25%를 resilient로 했다는데 한문항만 썼는지, 다른 문항들 전체를 썼는지는 확인 필요함"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.2 64-bit ('{huni}')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6759f8f029089d11794c1cc9cf7a24be0c22d8786d9aebb0d861f27dfe2c888b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
