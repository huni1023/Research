{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Current OS:  win32\n",
      ">> Current WD:  c:\\Users\\jhun1\\Proj\\Research\\MixedRF\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import copy\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "from sys import platform\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# unicode minus를 사용하지 않기 위한 설정 (minus 깨짐현상 방지)\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "plt.rcParams[\"figure.autolayout\"] = True\n",
    "\n",
    "# 설치된 폰트 출력\n",
    "import matplotlib.font_manager as fm\n",
    "font_list = [font.name for font in fm.fontManager.ttflist]\n",
    "plt.rcParams['font.family'] = 'Malgun Gothic'\n",
    "\n",
    "\n",
    "BASE_DIR = os.getcwd()\n",
    "print('>> Current OS: ', platform)\n",
    "print('>> Current WD: ', BASE_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>>> Init: load raw data\n",
      ">> Stu data set (6037, 1119)\n",
      ">> Sch data set (152, 197)\n",
      ">> Tch data set (3754, 351)\n"
     ]
    }
   ],
   "source": [
    "class Load:\n",
    "    def __init__(self, codeBook):\n",
    "        if 'darwin' in platform:\n",
    "            self.BASE_DIR = '/Users/huni/Dropbox/[3]Project/[혼합효과 랜덤포레스트_2022]'\n",
    "        else:\n",
    "            self.BASE_DIR = r'C:\\Users\\jhun1\\Dropbox\\[3]Project\\[혼합효과 랜덤포레스트_2022]'\n",
    "        \n",
    "        global BASE_DIR\n",
    "        codebook_Folder = 'drive-download-20220816T053902Z-001'\n",
    "\n",
    "        print('>>>>> Init: load raw data')\n",
    "        self.rawStu = pd.read_excel(os.path.join(BASE_DIR, 'data', 'rawData(HK).xlsx'), sheet_name='stu')\n",
    "        self.rawSCH = pd.read_excel(os.path.join(BASE_DIR, 'data', 'rawData(HK).xlsx'), sheet_name='sch')\n",
    "        self.rawTCH = pd.read_excel(os.path.join(BASE_DIR, 'data', 'rawData(HK).xlsx'), sheet_name='tch')\n",
    "        self.dataLS = [self.rawStu, self.rawSCH, self.rawTCH]\n",
    "\n",
    "        # desciptive\n",
    "        print('>> Stu data set', self.rawStu.shape)\n",
    "        print('>> Sch data set', self.rawSCH.shape)\n",
    "        print('>> Tch data set', self.rawTCH.shape)\n",
    "        \n",
    "        \n",
    "        self.cb = pd.read_excel(os.path.join(self.BASE_DIR, codebook_Folder, codeBook),\n",
    "                            skiprows=[0] # 맨 윗줄 제거\n",
    "                            )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Loader = Load(codeBook='TargetPaper_CODEBOOK.xlsx')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      ">>>> Cleaning: select variable\n",
      ">>>> 1. left only identified variable 30\n",
      "> cleaned : 28\n",
      "\n",
      ">>>> 2. drop useless variable\n",
      "> Stu data only left.. :  29\n",
      "> Sch data only left.. :  0\n",
      "> Tch data only left.. :  0\n",
      ">> before:  6037 >> after:  1459\n"
     ]
    }
   ],
   "source": [
    "class Preprocessing(Load):\n",
    "    def __init__(self, dataLS, cb):\n",
    "        # super().__init__(dataLS, codebook = cb)\n",
    "        self.dataLS = dataLS\n",
    "        self.cb = cb\n",
    "    \n",
    "    def defaultCleaner(self):\n",
    "        print('\\n\\n>>>> Cleaning: select variable')\n",
    "\n",
    "        ### slicing only codebook independent var\n",
    "        def drop_Unidentified_variable(codebook):\n",
    "            variable_name = list(codebook['variable_name'].values)\n",
    "            print('>>>> 1. left only identified variable', len(variable_name))\n",
    "            new = [variable for variable in variable_name if variable != '?']\n",
    "            print('> cleaned :', len(new))\n",
    "            return new\n",
    "\n",
    "\n",
    "        def cleaningVariable(dataLS, using_variable_list):\n",
    "            print('\\n>>>> 2. drop useless variable')\n",
    "\n",
    "            \"\"\"\n",
    "            1. iteration through data set (stu, sch, tch)\n",
    "            2. iteration through every column\n",
    "            3. save column when it is contained\n",
    "            \"\"\"\n",
    "            new_data_ls = {'Stu': [], 'Sch': [], 'Tch': []}\n",
    "\n",
    "            count = 0\n",
    "            for data_set, label in zip(dataLS, new_data_ls.keys()):\n",
    "                toDrop = []\n",
    "                for col in data_set.columns:\n",
    "                    if col in using_variable_list:\n",
    "                        count += 1\n",
    "                    \n",
    "                    elif col == 'ESCS':\n",
    "                        continue\n",
    "\n",
    "                    else:\n",
    "                        toDrop.append(col)\n",
    "                \n",
    "                newDF = data_set.drop(toDrop, axis=1)\n",
    "                new_data_ls[label] = newDF\n",
    "                print(f'> {label} data only left.. : ', len(newDF.columns))\n",
    "\n",
    "\n",
    "            assert count == len(using_variable_list), print('*error: ', count, \"...\", len(using_variable_list))\n",
    "            \n",
    "            return new_data_ls\n",
    "\n",
    "\n",
    "        var_ls =  drop_Unidentified_variable(self.cb) # cleaening unidentified variable\n",
    "        output = cleaningVariable(dataLS = self.dataLS, using_variable_list=var_ls)\n",
    "        self.cleaned = output['Stu']\n",
    "        assert type(self.cleaned) == pd.DataFrame\n",
    "\n",
    "        return None\n",
    "\n",
    "    def academic(self):\n",
    "        #!# 학문성취 계산해서, resilient 계산하기\n",
    "        pass\n",
    "    \n",
    "    def slice(self):\n",
    "        threshold = self.cleaned['ESCS'].quantile(0.25)\n",
    "        df = copy.deepcopy(self.cleaned)\n",
    "        before = df.shape[0]\n",
    "\n",
    "        toDrop = []\n",
    "        for idx, val in zip(df.index, df['ESCS'].values):\n",
    "            if val < threshold:\n",
    "                continue\n",
    "            else:\n",
    "                toDrop.append(idx)\n",
    "\n",
    "        output = df.drop(toDrop, axis = 0)\n",
    "        after = output.shape[0]\n",
    "        print('>> before: ', before, '>> after: ', after)\n",
    "        return output\n",
    "\n",
    "\n",
    "    \n",
    "preprocessor = Preprocessing(dataLS = Loader.dataLS, cb = Loader.cb)\n",
    "preprocessor.defaultCleaner()\n",
    "df = preprocessor.slice()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_excel(os.path.join(BASE_DIR, 'data', 'cleanedData(HK).xlsx'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SPSS 26.0의 MCMC 사용해서 결측치 대체함 \n",
    "# https://www.statisticshowto.com/missing-values-spss/\n",
    "\n",
    "\n",
    "# reading achivement top 25%를 resilient로 했다는데 한문항만 썼는지, 다른 문항들 전체를 썼는지는 확인 필요함"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('SNURO')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5702d5a1f35543d6c34eea9cfe7c421721e3098aad62c19242cc5f6d6a95c445"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
