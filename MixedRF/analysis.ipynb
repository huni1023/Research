{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 학업탄력성 영향요인 연구\n",
    "@author: sjh\n",
    "\n",
    "## 1. Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Current OS:  win32\n",
      ">> Current WD:  c:\\Users\\jhun1\\Proj\\Research\\MixedRF\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import copy\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "from sys import platform\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# unicode minus를 사용하지 않기 위한 설정 (minus 깨짐현상 방지)\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "plt.rcParams[\"figure.autolayout\"] = True\n",
    "\n",
    "# 설치된 폰트 출력\n",
    "import matplotlib.font_manager as fm\n",
    "font_list = [font.name for font in fm.fontManager.ttflist]\n",
    "plt.rcParams['font.family'] = 'Malgun Gothic'\n",
    "\n",
    "\n",
    "BASE_DIR = os.getcwd()\n",
    "print('>> Current OS: ', platform)\n",
    "print('>> Current WD: ', BASE_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Load:\n",
    "    def __init__(self, stuFolder, schFolder, tchFolder, codeBook,\n",
    "                onlyCodeBook, ):\n",
    "        if 'darwin' in platform:\n",
    "            self.BASE_DIR = '/Users/huni/Dropbox/[3]Project/[혼합효과 랜덤포레스트_2022]'\n",
    "        else:\n",
    "            if os.getlogin() == 'jhun1':\n",
    "                self.BASE_DIR = r'C:\\Users\\jhun1\\Dropbox\\[3]Project\\[혼합효과 랜덤포레스트_2022]'\n",
    "                \n",
    "            elif os.getlogin() == 'snukh':\n",
    "                self.BASE_DIR = r'C:\\Users\\snukh\\Downloads\\[혼합효과 랜덤포레스트_2022]' \n",
    "        rawData_Folder = 'PISA2018'\n",
    "        codebook_Folder = 'drive-download-20220816T053902Z-001'\n",
    "\n",
    "        if onlyCodeBook == False:\n",
    "            print('>>>>> Init: load raw data')\n",
    "            stuFile = [FILE for FILE in os.listdir(os.path.join(self.BASE_DIR, rawData_Folder, stuFolder)) if FILE[-4:] == '.sav'][0]\n",
    "            schFile = [FILE for FILE in os.listdir(os.path.join(self.BASE_DIR, rawData_Folder, schFolder)) if FILE[-4:] == '.sav'][0]\n",
    "            tchFile = [FILE for FILE in os.listdir(os.path.join(self.BASE_DIR, rawData_Folder, tchFolder)) if FILE[-4:] == '.sav'][0]\n",
    "\n",
    "            self.rawStu = pd.read_spss(os.path.join(self.BASE_DIR, rawData_Folder, stuFolder, stuFile))\n",
    "            self.rawSCH = pd.read_spss(os.path.join(self.BASE_DIR, rawData_Folder, schFolder, schFile))\n",
    "            self.rawTCH = pd.read_spss(os.path.join(self.BASE_DIR, rawData_Folder, tchFolder, tchFile))\n",
    "            self.dataLS = [self.rawStu, self.rawSCH, self.rawTCH]\n",
    "\n",
    "            # desciptive\n",
    "            print('>> Stu data set', self.rawStu.shape)\n",
    "            print('>> Sch data set', self.rawSCH.shape)\n",
    "            print('>> Tch data set', self.rawTCH.shape)\n",
    "        \n",
    "        else:\n",
    "            print('>> Only Codebook will be loaded')\n",
    "            pass\n",
    "        \n",
    "        self.cb = pd.read_excel(os.path.join(self.BASE_DIR, codebook_Folder, codeBook), sheet_name='변수선택(1213)')\n",
    "\n",
    "\n",
    "\n",
    "    def defaultCleaner(self):\n",
    "        print('\\n\\n>>>> Cleaning: default nation and variable')\n",
    "\n",
    "\n",
    "        ### dictionary by nation\n",
    "        def cleaningNational(dataLS, SouthKorea = 'Korea', US='United States'):\n",
    "            nationalData = {'SK': [], 'US': []}\n",
    "\n",
    "            for nation_name, code in zip(nationalData.keys(), [SouthKorea, US]):\n",
    "                print(f'\\n>> slicing: {nation_name}')\n",
    "                for data in dataLS:\n",
    "                    # print(data.head(5))\n",
    "                    temp2 = data[data['CNTRYID'] == code]\n",
    "                \n",
    "                    nationalData[nation_name].append(temp2)\n",
    "                    print('>> sliced shape: ', temp2.shape)\n",
    "            \n",
    "            return nationalData\n",
    "            \n",
    "\n",
    "        def cleaningVariable(data, codeBook):\n",
    "            output = {}\n",
    "            \n",
    "            for nation_name in data.keys():\n",
    "                Column_toSave = {'Stu': [], 'Sch': [], 'Tch': []}\n",
    "                for fileName, variable, category in tqdm(zip(codeBook['file name'].values, codeBook['NAME'].values, codeBook['categories']), desc=\">> variable check\"):\n",
    "                    # 코드북 내에서도 분석에서 제할 변수는 file name을 비움\n",
    "                    if type(fileName) != str:\n",
    "                        continue\n",
    "\n",
    "\n",
    "                    else: \n",
    "                        if category == 'identifier':\n",
    "                            Column_toSave['Stu'].append(variable)\n",
    "                            \n",
    "                            if variable == 'CNTSTUID':\n",
    "                                continue\n",
    "                            else: # 코드북 구조 문제: 학교, 교사 셋에는 해당 변수가 없어서 추가해줌\n",
    "                                Column_toSave['Sch'].append(variable)\n",
    "                                Column_toSave['Tch'].append(variable)\n",
    "\n",
    "                        else:\n",
    "                            if 'STU' in fileName:\n",
    "                                if variable in data[nation_name][0].columns:\n",
    "                                    Column_toSave['Stu'].append(variable)\n",
    "                                else:\n",
    "                                    print('>> none(stu)', variable)\n",
    "\n",
    "                            elif 'SCH' in fileName:\n",
    "                                if variable in data[nation_name][1].columns:\n",
    "                                    Column_toSave['Sch'].append(variable)\n",
    "                                else:\n",
    "                                    print('>> none(sch)', variable)\n",
    "\n",
    "                            elif 'TCH' in fileName:\n",
    "                                if variable in data[nation_name][2].columns:\n",
    "                                    Column_toSave['Tch'].append(variable)\n",
    "                                else:\n",
    "                                    print('>> none(tch)', variable)\n",
    "                    \n",
    "                \n",
    "                # print('>>>> save: ', Column_toSave)\n",
    "                output[nation_name] = [data[nation_name][0][Column_toSave['Stu']],\n",
    "                                        data[nation_name][1][Column_toSave['Sch']],\n",
    "                                        data[nation_name][2][Column_toSave['Tch']],\n",
    "                                        ]\n",
    "                assert len(Column_toSave['Tch']) < 4, print(Column_toSave['Tch'])\n",
    "\n",
    "            assert 'SK' in output.keys()\n",
    "            assert 'US' in output.keys()\n",
    "            return output\n",
    "\n",
    "        cleaned_Nation = cleaningNational(dataLS = self.dataLS)\n",
    "        self.default_cleaningData = cleaningVariable(data = cleaned_Nation, codeBook = self.cb)\n",
    "\n",
    "        # categories 에서 일단은 codebook에 있는 변수가 다 있나 확인\n",
    "        # categories 에서 individual & family, school 구분"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Only Codebook will be loaded\n"
     ]
    }
   ],
   "source": [
    "LOAD_ONLY_CODEBOOK = True\n",
    "\n",
    "Loader = Load(stuFolder=\"STU\", schFolder='SCH', tchFolder='TCH',\n",
    "                onlyCodeBook = LOAD_ONLY_CODEBOOK,\n",
    "                codeBook='PISA2018_CODEBOOK (변수선택-공유).xlsx'\n",
    "                )\n",
    "\n",
    "if LOAD_ONLY_CODEBOOK == False:\n",
    "    Loader.defaultCleaner()\n",
    "    print(Loader.default_cleaningData.keys())\n",
    "\n",
    "    with pd.ExcelWriter(os.path.join(BASE_DIR, 'data', 'cleanedData(SK).xlsx')) as writer:\n",
    "        Loader.default_cleaningData['SK'][0].to_excel(writer, sheet_name='stu', index=False)\n",
    "        Loader.default_cleaningData['SK'][1].to_excel(writer, sheet_name='sch', index=False)\n",
    "        Loader.default_cleaningData['SK'][2].to_excel(writer, sheet_name='tch', index=False) \n",
    "\n",
    "\n",
    "    with pd.ExcelWriter(os.path.join(BASE_DIR, 'data', 'cleanedData(US).xlsx')) as writer:\n",
    "        Loader.default_cleaningData['US'][0].to_excel(writer, sheet_name='stu', index=False)\n",
    "        Loader.default_cleaningData['US'][1].to_excel(writer, sheet_name='sch', index=False)\n",
    "        Loader.default_cleaningData['US'][2].to_excel(writer, sheet_name='tch', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "minor thing, for replicate hong kong paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ls_hk = []\n",
    "# for data in Loader.dataLS:\n",
    "#     df = data[data['CNTRYID'] == 'Hong Kong']\n",
    "#     ls_hk.append(df)\n",
    "#     print('>> ', df.shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with pd.ExcelWriter(os.path.join(BASE_DIR, 'data', 'rawData(HK).xlsx')) as writer:\n",
    "#     ls_hk[0].to_excel(writer, sheet_name='stu', index=False)\n",
    "#     ls_hk[1].to_excel(writer, sheet_name='sch', index=False)\n",
    "#     ls_hk[2].to_excel(writer, sheet_name='tch', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 앞선 처리 데이터 불러오기\n",
    "loadedData = {'SK': [\n",
    "            pd.read_excel(os.path.join(BASE_DIR,'data', 'cleanedData(SK).xlsx'), sheet_name='stu'),\n",
    "            pd.read_excel(os.path.join(BASE_DIR,'data', 'cleanedData(SK).xlsx'), sheet_name='sch'),\n",
    "            pd.read_excel(os.path.join(BASE_DIR,'data', 'cleanedData(SK).xlsx'), sheet_name='tch'),\n",
    "            \n",
    "            ],\n",
    "        'US': [\n",
    "            pd.read_excel(os.path.join(BASE_DIR,'data', 'cleanedData(US).xlsx'), sheet_name='stu'),\n",
    "            pd.read_excel(os.path.join(BASE_DIR,'data', 'cleanedData(US).xlsx'), sheet_name='sch'),\n",
    "            pd.read_excel(os.path.join(BASE_DIR,'data', 'cleanedData(US).xlsx'), sheet_name='tch'),\n",
    "            ]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> test NA column:  SK\n",
      "stu\n",
      "sch\n",
      ">> test NA column:  US\n",
      "stu\n",
      ">>> over 80% is NA:  PERSPECT\n",
      "sch\n",
      "\n",
      "\n",
      ">>>> 1. Dummy coding\n",
      "\n",
      "\n",
      ">>>> 2. Join DataFrame\n",
      ">> join nation:  SK\n",
      ">> school data is empty\n",
      ">> join nation:  US\n",
      ">> school data is empty\n",
      "\n",
      "\n",
      ">>>> 3. Verify na and Drop student\n",
      "dict_keys(['SK', 'US'])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1224x432 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> NA drop:  29\n",
      ">> NA drop:  119\n",
      "\n",
      "\n",
      ">>>> 4. Slicing data by ESCS\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'ESCS'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\jhun1\\anaconda3\\envs\\khrrc\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3621\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3620\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 3621\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[0;32m   3622\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[1;32mc:\\Users\\jhun1\\anaconda3\\envs\\khrrc\\lib\\site-packages\\pandas\\_libs\\index.pyx:136\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\jhun1\\anaconda3\\envs\\khrrc\\lib\\site-packages\\pandas\\_libs\\index.pyx:163\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5198\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5206\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'ESCS'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\jhun1\\Proj\\Research\\MixedRF\\analysis.ipynb Cell 12\u001b[0m in \u001b[0;36m<cell line: 465>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/jhun1/Proj/Research/MixedRF/analysis.ipynb#X15sZmlsZQ%3D%3D?line=462'>463</a>\u001b[0m processor\u001b[39m.\u001b[39mJoin()\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/jhun1/Proj/Research/MixedRF/analysis.ipynb#X15sZmlsZQ%3D%3D?line=463'>464</a>\u001b[0m processor\u001b[39m.\u001b[39mDropStudent()\n\u001b[1;32m--> <a href='vscode-notebook-cell:/c%3A/Users/jhun1/Proj/Research/MixedRF/analysis.ipynb#X15sZmlsZQ%3D%3D?line=464'>465</a>\u001b[0m processor\u001b[39m.\u001b[39;49mESCS(test_key\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mread_10\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/jhun1/Proj/Research/MixedRF/analysis.ipynb#X15sZmlsZQ%3D%3D?line=465'>466</a>\u001b[0m processor\u001b[39m.\u001b[39mshouldBeCalculated()\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/jhun1/Proj/Research/MixedRF/analysis.ipynb#X15sZmlsZQ%3D%3D?line=466'>467</a>\u001b[0m processor\u001b[39m.\u001b[39mAdjustMinor()\n",
      "\u001b[1;32mc:\\Users\\jhun1\\Proj\\Research\\MixedRF\\analysis.ipynb Cell 12\u001b[0m in \u001b[0;36mPreprocessing.ESCS\u001b[1;34m(self, test_key)\u001b[0m\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/jhun1/Proj/Research/MixedRF/analysis.ipynb#X15sZmlsZQ%3D%3D?line=323'>324</a>\u001b[0m     plt\u001b[39m.\u001b[39mshow()\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/jhun1/Proj/Research/MixedRF/analysis.ipynb#X15sZmlsZQ%3D%3D?line=325'>326</a>\u001b[0m \u001b[39m## 1. calculate threshold value\u001b[39;00m\n\u001b[1;32m--> <a href='vscode-notebook-cell:/c%3A/Users/jhun1/Proj/Research/MixedRF/analysis.ipynb#X15sZmlsZQ%3D%3D?line=326'>327</a>\u001b[0m AcademicThreshold, newData_dict \u001b[39m=\u001b[39m thresholdCalculator(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_3_dropNa,\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/jhun1/Proj/Research/MixedRF/analysis.ipynb#X15sZmlsZQ%3D%3D?line=327'>328</a>\u001b[0m                                                     test_key\u001b[39m=\u001b[39;49mtest_key) \u001b[39m## 학업성취 코딩 방법을 바꿀 때 여기 arg를 조정\u001b[39;00m\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/jhun1/Proj/Research/MixedRF/analysis.ipynb#X15sZmlsZQ%3D%3D?line=328'>329</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m>> 학문성취 상위 75%: 우리나라.. \u001b[39m\u001b[39m{\u001b[39;00mAcademicThreshold[\u001b[39m'\u001b[39m\u001b[39mSK\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m'\u001b[39m\u001b[39macademic_score\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m}\u001b[39;00m\u001b[39m, 미국.. \u001b[39m\u001b[39m{\u001b[39;00mAcademicThreshold[\u001b[39m'\u001b[39m\u001b[39mUS\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m'\u001b[39m\u001b[39macademic_score\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/jhun1/Proj/Research/MixedRF/analysis.ipynb#X15sZmlsZQ%3D%3D?line=331'>332</a>\u001b[0m \u001b[39m## 2. slice\u001b[39;00m\n",
      "\u001b[1;32mc:\\Users\\jhun1\\Proj\\Research\\MixedRF\\analysis.ipynb Cell 12\u001b[0m in \u001b[0;36mPreprocessing.ESCS.<locals>.thresholdCalculator\u001b[1;34m(inputData, test_key)\u001b[0m\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/jhun1/Proj/Research/MixedRF/analysis.ipynb#X15sZmlsZQ%3D%3D?line=234'>235</a>\u001b[0m     \u001b[39m# threshold[nationalName]['academic_score'] = inputNational['AcademicScore'].quantile(0.75)\u001b[39;00m\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/jhun1/Proj/Research/MixedRF/analysis.ipynb#X15sZmlsZQ%3D%3D?line=235'>236</a>\u001b[0m     threshold[nationalName][\u001b[39m'\u001b[39m\u001b[39macademic_score\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m \u001b[39m563\u001b[39m \u001b[39m#!# 수동으로 조정해줘야 함\u001b[39;00m\n\u001b[1;32m--> <a href='vscode-notebook-cell:/c%3A/Users/jhun1/Proj/Research/MixedRF/analysis.ipynb#X15sZmlsZQ%3D%3D?line=236'>237</a>\u001b[0m     threshold[nationalName][\u001b[39m'\u001b[39m\u001b[39mescs_score\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m inputNational[\u001b[39m'\u001b[39;49m\u001b[39mESCS\u001b[39;49m\u001b[39m'\u001b[39;49m]\u001b[39m.\u001b[39mquantile(\u001b[39m0.25\u001b[39m)\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/jhun1/Proj/Research/MixedRF/analysis.ipynb#X15sZmlsZQ%3D%3D?line=238'>239</a>\u001b[0m \u001b[39mreturn\u001b[39;00m threshold, inputData\n",
      "File \u001b[1;32mc:\\Users\\jhun1\\anaconda3\\envs\\khrrc\\lib\\site-packages\\pandas\\core\\frame.py:3505\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3503\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mnlevels \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m   3504\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 3505\u001b[0m indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49mget_loc(key)\n\u001b[0;32m   3506\u001b[0m \u001b[39mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   3507\u001b[0m     indexer \u001b[39m=\u001b[39m [indexer]\n",
      "File \u001b[1;32mc:\\Users\\jhun1\\anaconda3\\envs\\khrrc\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3623\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3621\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine\u001b[39m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3622\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[1;32m-> 3623\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[0;32m   3624\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[0;32m   3625\u001b[0m     \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3626\u001b[0m     \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3627\u001b[0m     \u001b[39m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3628\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'ESCS'"
     ]
    }
   ],
   "source": [
    "class Preprocessing:\n",
    "    def __init__(self, LoadedData, codeBook, dummyCodeBook):\n",
    "        self.data = LoadedData\n",
    "        self.cb = codeBook\n",
    "        with open(dummyCodeBook, encoding='utf-8') as json_file:\n",
    "            self.dummyCB = json.load(json_file)\n",
    "        self.testBook = {\n",
    "                    'read/math/sci_1': 'PV1MATH PV1READ PV1SCIE'.split(),\n",
    "                    'read/math_1': 'PV1MATH PV1READ'.split(),\n",
    "                    'read/math_10': 'PV1MATH PV2MATH PV3MATH PV4MATH PV5MATH PV6MATH PV7MATH PV8MATH PV9MATH PV10MATH PV1READ PV2READ PV3READ PV4READ PV5READ PV6READ PV7READ PV8READ PV9READ PV10READ'.split(),\n",
    "                    'read_1': ['PV1READ'],\n",
    "                    'read_10': 'PV1READ PV2READ PV3READ PV4READ PV5READ PV6READ PV7READ PV8READ PV9READ PV10READ'.split()\n",
    "                }\n",
    "\n",
    "        self._1_dummy = {}\n",
    "        self._2_joined = {}\n",
    "        self._3_dropNa = {}\n",
    "        self._4_ESCS = {'full': {}, 'sliced': {}} # 여기서 데이터 갈라야함\n",
    "        self._5_shouldBeCal = {}\n",
    "        self.finalRS = {}\n",
    "        \n",
    "        self.rs_1_columnFull = pd.DataFrame()\n",
    "        self.rs_1_columnSK = pd.DataFrame()\n",
    "        self.rs_1_columnUS = pd.DataFrame()\n",
    "        \n",
    "\n",
    "    ### Needs1. is selected variable contained in both dataset\n",
    "    def noDataColumn(self): # 열별로 계산\n",
    "        toDrop = {}\n",
    "        \n",
    "        for nationName, nationalData in self.data.items():\n",
    "            print('>> test NA column: ', nationName)\n",
    "\n",
    "            toDrop[nationName] = []\n",
    "            for idx, (label, inputDf) in enumerate(zip('stu sch tch'.split(), nationalData)):\n",
    "                if label == 'tch':\n",
    "                    continue\n",
    "                else:\n",
    "                    print(label)\n",
    "                    for column in inputDf.columns:\n",
    "                        if inputDf[column].isna().sum() > (inputDf.shape[0] * 0.8):\n",
    "                            print('>>> over 80% is NA: ', column)\n",
    "                            toDrop[nationName].append(column)\n",
    "                        \n",
    "                        elif 'missing' in inputDf[column].values:\n",
    "                            print('>>> missing: ', column)\n",
    "                            toDrop[nationName].append(column)\n",
    "                        \n",
    "                        else:\n",
    "                            continue\n",
    "        return toDrop\n",
    "            # assert len(toDrop[nationName]) == 2, print(toDrop)\n",
    "\n",
    "\n",
    "    def Dummy(self, doDummy):\n",
    "        # match key and value from codeBook\n",
    "        print('\\n\\n>>>> 1. Dummy coding')\n",
    "        def matchKV(codeBookDict, inputList):\n",
    "            outputLS = []\n",
    "            for val in inputList:\n",
    "                try:\n",
    "                    outputLS.append(codeBookDict[val])\n",
    "                except KeyError:\n",
    "                    outputLS.append(np.nan)\n",
    "            \n",
    "            return outputLS\n",
    "        \n",
    "        if doDummy == True:\n",
    "            notDummyCol1 = self.cb[self.cb['categories'] == 'identifier'].index\n",
    "            notDummyCol2 = self.cb[self.cb['categories'] == 'resilient status'].index\n",
    "            notDummyCol3 = self.cb[self.cb['file name'] == 'should be caculated'].index\n",
    "            \n",
    "            toDummy = self.cb.drop(list(notDummyCol1)+list(notDummyCol2)+list(notDummyCol3), axis=0) # 더미 변환 안할 변수 행 삭제함\n",
    "            # display(toDummy)\n",
    "\n",
    "            for nationalName, inputNational in self.data.items():\n",
    "                outputNational = copy.deepcopy(inputNational)\n",
    "\n",
    "                for idx, row in toDummy.iterrows(): # 변수별로 반복문\n",
    "                    variable = row['NAME']\n",
    "                    \n",
    "                    if type(row['file name']) != str: # 분석에서 제외할 변수가 있어서 버림\n",
    "                        continue\n",
    "\n",
    "                    else:\n",
    "                        if ('STU' in row['file name']) and (variable in self.dummyCB['stu']):\n",
    "                            outputLS = matchKV(self.dummyCB['stu'][variable], outputNational[0][variable])\n",
    "                            outputNational[0][variable] = outputLS \n",
    "\n",
    "                    # 학교, 교사 데이터는 더미코딩할 것 없음\n",
    "                self._1_dummy[nationalName] = outputNational\n",
    "        elif doDummy == False:\n",
    "            self._1_dummy = copy.deepcopy(self.data)\n",
    "        else:\n",
    "            raise TypeError('>> Error: check option Type')\n",
    "\n",
    "\n",
    "    def Join(self):\n",
    "        print('\\n\\n>>>> 2. Join DataFrame')\n",
    "\n",
    "        for nationalName, inputNational in self._1_dummy.items():\n",
    "            print('>> join nation: ', nationalName)\n",
    "            inputNational[0].reset_index(drop=True, inplace=True)\n",
    "            \n",
    "            outputDf = copy.deepcopy(inputNational[0])\n",
    "            # print('>> before ', outputDf.shape)\n",
    "            before = outputDf.shape\n",
    "\n",
    "\n",
    "            inputNational[1].drop(['CNTRYID', 'CNT'], axis=1, inplace=True)\n",
    "            if inputNational[1].index.name == 'CNTSCHID':\n",
    "                pass\n",
    "            else:\n",
    "                inputNational[1].set_index('CNTSCHID', drop=True, inplace=True)\n",
    "            \n",
    "            if inputNational[1].shape[1] == 0:\n",
    "                print('>> school data is empty')\n",
    "                pass\n",
    "            else:\n",
    "                for idx, row in tqdm(outputDf.iterrows(), desc=\">> mapping\"):\n",
    "                    toBeInput = inputNational[1].loc[row['CNTSCHID']].values # 학생 데이터에 들어가야할 학교 데이터 찾기\n",
    "                    assert len(toBeInput) == inputNational[1].shape[1]\n",
    "                    \n",
    "                    toBeInput_T = toBeInput.reshape(1, 8)\n",
    "                    outputDf.loc[idx, list(inputNational[1].columns)] = toBeInput_T[0]\n",
    "            \n",
    "                after = outputDf.shape\n",
    "                print('>>>> Bef: ', before, '....', 'Aft: ', after)\n",
    "                assert 'EDUSHORT' in outputDf.columns\n",
    "\n",
    "            self._2_joined[nationalName] = outputDf\n",
    "\n",
    "    def DropStudent(self):\n",
    "        # 각 column 별로 데이터 검수\n",
    "        print('\\n\\n>>>> 3. Verify na and Drop student')\n",
    "        print(self._2_joined.keys())\n",
    "        def column_wise(inputData):\n",
    "            if type(inputData) == dict:\n",
    "                merged = pd.concat([inputData['SK'], inputData['US']])\n",
    "                assert merged.shape[0] == inputData['SK'].shape[0] + inputData['US'].shape[0]\n",
    "            elif type(inputData) == pd.DataFrame:\n",
    "                merged = copy.deepcopy(inputData)\n",
    "            \n",
    "            else:\n",
    "                raise TypeError('>> Error: Check your input D type')\n",
    "                \n",
    "\n",
    "            describeDF = merged.describe().T\n",
    "            describeDF['NA_ratio'] = round(\n",
    "                100 - describeDF['count']/merged.shape[0]*100,\n",
    "                 2\n",
    "                 )\n",
    "\n",
    "            newColumnOrder = [describeDF.columns[0], 'NA_ratio'] + list(describeDF.columns[1:-1])\n",
    "            describeDF= describeDF[newColumnOrder]\n",
    "            return describeDF\n",
    "\n",
    "        # 각 학생별로 데이터 검수\n",
    "        def row_wise(inputData):\n",
    "            merged = pd.concat([inputData['SK'], inputData['US']])\n",
    "            assert merged.shape[0] == inputData['SK'].shape[0] + inputData['US'].shape[0]\n",
    "            # unlike column wise, we prepare data with \n",
    "\n",
    "            for_histogram = {}\n",
    "            for label, data in zip(['full', 'SK', 'US'], [merged, inputData['SK'], inputData['US']]):\n",
    "                for_histogram[label] = []\n",
    "\n",
    "                for i in range(len(data.index)) :\n",
    "                    na_ratio = round((data.iloc[i].isnull().sum()/data.shape[1]) * 100, 0)\n",
    "                    for_histogram[label].append(na_ratio)\n",
    "\n",
    "            fig = plt.figure(figsize=(17,6))\n",
    "\n",
    "            plt.subplot(1, 3, 1)\n",
    "            plt.hist(for_histogram['full'])\n",
    "            plt.title('\\n전체 데이터\\n')\n",
    "            plt.xlabel('\\n전체 변수 대비 결측비율(%)\\n')\n",
    "            plt.ylabel('빈도')\n",
    "            \n",
    "            plt.subplot(1, 3, 2)\n",
    "            plt.hist(for_histogram['SK'])\n",
    "            plt.title('\\nSouth Korea\\n')\n",
    "            plt.xlabel('\\n전체 변수 대비 결측비율(%)\\n')\n",
    "            plt.ylabel('빈도')\n",
    "            \n",
    "            plt.subplot(1, 3, 3)\n",
    "            plt.hist(for_histogram['US'])\n",
    "            plt.title('\\nUnited States\\n')\n",
    "            plt.xlabel('\\n전체 변수 대비 결측비율(%)\\n')\n",
    "            plt.ylabel('빈도')\n",
    "\n",
    "            plt.savefig(os.path.join(BASE_DIR, 'data', f'NA_ratio.jpg'))\n",
    "            plt.show()\n",
    "\n",
    "            return for_histogram\n",
    "        \n",
    "        def dropOver(inputData, rowWiseResult):\n",
    "            assert type(rowWiseResult) == list\n",
    "            output = copy.deepcopy(inputData)\n",
    "\n",
    "            toDrop = []\n",
    "            for idx, sumNA in zip(output.index, rowWiseResult):\n",
    "                if sumNA > 30:\n",
    "                    toDrop.append(idx)\n",
    "            \n",
    "            before = output.shape[0]\n",
    "            output.drop(toDrop, axis=0, inplace=True)\n",
    "            after = output.shape[0]\n",
    "            print('>> NA drop: ', before - after)\n",
    "\n",
    "            return output\n",
    "        \n",
    "        self.rs_1_columnFull = column_wise(self._2_joined)\n",
    "        self.rs_1_columnSK = column_wise(self._2_joined['SK'])\n",
    "        self.rs_1_columnUS = column_wise(self._2_joined['US'])\n",
    "\n",
    "        rowWiseNA = row_wise(self._2_joined)\n",
    "        self._3_dropNa['SK'] = dropOver(self._2_joined['SK'], rowWiseResult=rowWiseNA['SK'])\n",
    "        self._3_dropNa['US'] = dropOver(self._2_joined['US'], rowWiseResult=rowWiseNA['US'])\n",
    "        \n",
    "        \n",
    "    def ESCS(self, score_calculating_method, *slicing_args):\n",
    "        # 데이터를 두개 만들어야함, result, resultSlice\n",
    "        # '''\n",
    "        # 1. score_calculating_method:\n",
    "        # 'mean' : mean of variables more than 1\n",
    "        # 'level': cutting manually decided score\n",
    "        # arg1. test_key : if 'score_calculating_method'\n",
    "        # arg2. Threshold_Reading_Score : score value\n",
    "        # '''\n",
    "        print('\\n\\n>>>> 4. Slicing data by ESCS')\n",
    "        \n",
    "        def thresholdCalculator(inputData,\n",
    "                                score_calculating_method, \n",
    "                                academic_slicing_info):\n",
    "            \n",
    "            threshold = {'SK': {}, 'US': {}}\n",
    "\n",
    "            for nationalName, inputNational in inputData.items():\n",
    "                # cal academic score\n",
    "                if score_calculating_method == 'mean':\n",
    "                    assert type(academic_slicing_info) == str, print('Insert validate type args')\n",
    "                    targetColumn = self.testBook[academic_slicing_info]\n",
    "                    inputNational['AcademicScore'] = inputNational.loc[:, targetColumn].mean(axis=1)\n",
    "                    threshold[nationalName]['academic_score'] = inputNational['AcademicScore'].quantile(0.75)\n",
    "                elif score_calculating_method == 'level':\n",
    "                    assert type(academic_slicing_info) == int, print('Insert validate type args')\n",
    "                    threshold[nationalName]['academic_score'] = academic_slicing_info #!# 수동으로 조정해줘야 함\n",
    "                else:\n",
    "                    raise ValueError(\"Specify right method\")\n",
    "                \n",
    "                # cal escs score\n",
    "                threshold[nationalName]['escs_score'] = inputNational['ESCS'].quantile(0.25)\n",
    "\n",
    "            return threshold, inputData # 새로운 열이 추가되었으므로 리턴해서 사용해야함\n",
    "        \n",
    "        def escsSlice(inputDict, escsThreshold):\n",
    "            assert type(inputDict) == dict, print('>> Error: must input Dict')\n",
    "            assert type(escsThreshold) == dict\n",
    "            output = {'SK': pd.DataFrame(), 'US': pd.DataFrame()}\n",
    "            for nationalName, inputNational in inputDict.items():\n",
    "                \n",
    "                before = inputNational.shape[0]\n",
    "                toDrop = []\n",
    "                for idx, val in zip(inputNational['ESCS'].index, inputNational['ESCS'].values):\n",
    "                    if val < escsThreshold[nationalName]['escs_score']:\n",
    "                        continue\n",
    "                    else:\n",
    "                        toDrop.append(idx) # escs 하위 25%를 넘는 친구들은 버림\n",
    "                \n",
    "                \n",
    "                output[nationalName] = inputNational.drop(toDrop, axis=0)\n",
    "                after = output[nationalName].shape[0]\n",
    "                print('>> before: ', before, '>> after: ', after)\n",
    "            \n",
    "            return output\n",
    "\n",
    "\n",
    "        def quantileCalculator( \n",
    "                            inputData, # 전체 Full, escs 하위 25%로 데이터셋이 2개로 나뉘므로 인풋을 줘야함\n",
    "                            option, # full: 전체 데이터, sliced: 잘린 데이터\n",
    "                            AcademicThreshold\n",
    "                            ):\n",
    "            \n",
    "            assert type(AcademicThreshold) == dict\n",
    "            print('\\n>> Option: ', option)\n",
    "\n",
    "            output = {'SK': pd.DataFrame(), 'US': pd.DataFrame()}\n",
    "            for IDX, (nationalName, inputNational) in enumerate(inputData.items()):\n",
    "                total = inputNational.shape[0]\n",
    "                \n",
    "                iamResilient = []\n",
    "                if option == 'full':\n",
    "                    escsVar = inputNational['ESCS'].quantile(0.25) # 하위 25%\n",
    "                    for idx, row in inputNational.iterrows():\n",
    "                        if row['AcademicScore'] > AcademicThreshold[nationalName]['academic_score'] and row['ESCS'] < AcademicThreshold[nationalName]['escs_score']: # sliced 데이터에서는 이 기준을 만족할 수 없음\n",
    "                            iamResilient.append(1)\n",
    "                        else:\n",
    "                            iamResilient.append(0)\n",
    "\n",
    "                elif option == 'sliced':\n",
    "                    for idx, row in inputNational.iterrows():\n",
    "                        if row['AcademicScore'] > AcademicThreshold[nationalName]['academic_score']: # sliced 데이터는 escs 기준 필요 없음\n",
    "                            iamResilient.append(1)\n",
    "                        else:\n",
    "                            iamResilient.append(0)\n",
    "\n",
    "                inputNational['resilient'] = iamResilient\n",
    "                resilientCount = [x for x in iamResilient if x ==1]\n",
    "                print(f'>> 회복탄력성 학생수({nationalName}): ', len(resilientCount), f'({round(len(resilientCount)/total*100, 2)})%')\n",
    "\n",
    "                output[nationalName] = inputNational\n",
    "\n",
    "            return output\n",
    "\n",
    "        def visualize(inputData,\n",
    "                    option, # full: 전체 데이터, sliced: 잘린 데이터\n",
    "                    figName, # 그림 제목\n",
    "                    AcademicThreshold\n",
    "                        ):\n",
    "\n",
    "            fig = plt.figure(figsize=(17,9))\n",
    "            for IDX, (nationalName, inputNational) in enumerate(inputData.items()):\n",
    "\n",
    "                plt.subplot(2, 2, 2*IDX+1)\n",
    "                plt.hist(inputNational['AcademicScore'])\n",
    "                plt.title(f'\\n학업성취{nationalName}\\n')\n",
    "                plt.xlabel('\\n점수\\n')\n",
    "                plt.axvline(AcademicThreshold[nationalName]['academic_score'], color='r', linewidth=1, linestyle='--')\n",
    "                \n",
    "                plt.subplot(2, 2, 2*IDX+2)\n",
    "                plt.hist(inputNational['ESCS'])\n",
    "                plt.title(f'\\n사회문화경제{nationalName}\\n')\n",
    "                plt.xlabel('\\n점수\\n')\n",
    "                if option=='full':\n",
    "                    plt.axvline(AcademicThreshold[nationalName]['escs_score'], color='r', linewidth=1, linestyle='--')\n",
    "\n",
    "                \n",
    "            plt.savefig(os.path.join(BASE_DIR, 'data', f'{figName}_{option}.jpg'))\n",
    "            plt.show()\n",
    "        \n",
    "        ## 1. calculate threshold value\n",
    "        AcademicThreshold, newData_dict = thresholdCalculator(self._3_dropNa,\n",
    "                                                            score_calculating_method = score_calculating_method,\n",
    "                                                            academic_slicing_info=slicing_args) ## 학업성취 코딩 방법을 바꿀 때 여기 arg를 조정\n",
    "        print(f\">> 학문성취 상위 75%: 우리나라.. {AcademicThreshold['SK']['academic_score']}, 미국.. {AcademicThreshold['US']['academic_score']}\")\n",
    "        \n",
    "        \n",
    "        ## 2. slice\n",
    "        self._4_ESCS['full'] = copy.deepcopy(newData_dict) # no drop case, so just copied\n",
    "        self._4_ESCS['sliced'] = escsSlice(newData_dict, escsThreshold = AcademicThreshold)\n",
    "        assert type(self._4_ESCS['full']) == dict, print(self._4_ESCS['full'])\n",
    "\n",
    "\n",
    "        ## 3. labeling resilient student\n",
    "        self._4_ESCS['full'] = quantileCalculator(inputData=self._4_ESCS['full'], \n",
    "                                                option = 'full',\n",
    "                                                AcademicThreshold= AcademicThreshold)\n",
    "        self._4_ESCS['sliced'] = quantileCalculator(inputData=self._4_ESCS['sliced'], \n",
    "                                                option = 'sliced',\n",
    "                                                AcademicThreshold= AcademicThreshold)\n",
    "\n",
    "        ## 4. visualize resilient student\n",
    "        visualize(self._4_ESCS['full'], option='full', figName='읽10', AcademicThreshold= AcademicThreshold)\n",
    "        visualize(self._4_ESCS['sliced'], option = 'sliced', figName ='읽10(target paper)', AcademicThreshold= AcademicThreshold)\n",
    "\n",
    "    \n",
    "    # should be calculated 변수들 계산하는 것임\n",
    "    def shouldBeCalculated(self):\n",
    "        print('\\n\\n>>>> 6. Should Be Calculated')\n",
    "        \n",
    "        def schoolMean(inputDf, whichVar):\n",
    "            assert type(whichVar) == list\n",
    "            outputMean = {}\n",
    "            for sch_id in inputDf['CNTSCHID'].values:\n",
    "                # print('>> ', sch_id)\n",
    "                if sch_id in outputMean.keys():\n",
    "                    continue\n",
    "                \n",
    "                else:\n",
    "                    temp1 = inputDf[inputDf['CNTSCHID'] == sch_id]\n",
    "                    temp2 = temp1.loc[:, whichVar] \n",
    "                    assert len(temp2.columns) == len(whichVar)\n",
    "                    meanVal = np.nanmean(temp2.values)\n",
    "                    assert type(meanVal) == np.float64, print('Error : ', type(meanVal))\n",
    "\n",
    "                    outputMean[sch_id] = meanVal\n",
    "            \n",
    "            return outputMean\n",
    "        \n",
    "        \n",
    "        def meanMapping(inputColumn, mean_dict):\n",
    "            outputLS = []\n",
    "            for idx, sch_id in enumerate(inputColumn.values):\n",
    "                outputLS.append(mean_dict[sch_id])\n",
    "\n",
    "            return outputLS\n",
    "        \n",
    "\n",
    "        def matching(inputData, codeBook):\n",
    "            output = copy.deepcopy(inputData)\n",
    "            shouldBeCal = self.cb[self.cb['file name'] == 'should be caculated']\n",
    "            assert len(shouldBeCal) == 2, print('Error: check self.cb')\n",
    "            for national in output.keys():\n",
    "                beforeShape = output[national].shape[1]\n",
    "                \n",
    "                calVal = list(codeBook[codeBook['categories'] == 'resilient status']['NAME'])\n",
    "                calVal.remove('ESCS')\n",
    "                \n",
    "                for variable in shouldBeCal['NAME'].values:\n",
    "                \n",
    "                    if variable == 'AVG_S_TEST':    \n",
    "                        mean_dict = schoolMean(output[national], calVal)\n",
    "                        \n",
    "                    elif variable == 'AVG_S_ESCS':\n",
    "                        mean_dict = schoolMean(output[national], ['ESCS'])\n",
    "\n",
    "                    #평균 dict 활용해서 매칭 진행\n",
    "                    outputLS = meanMapping(output[national]['CNTSCHID'], mean_dict)\n",
    "                    assert len(outputLS) == output[national].shape[0], print('Error: ', len(outputLS))\n",
    "                    output[national][variable] = outputLS # 학교 데이터이므로, 학교에 맞춰서 추가하기\n",
    "\n",
    "                afterShape = output[national].shape[1]\n",
    "                assert afterShape - beforeShape == 2, print('Beofre: ', beforeShape, ' ... ', 'After: ', afterShape)\n",
    "            \n",
    "            return output\n",
    "\n",
    "        self._5_shouldBeCal['full'] = matching(self._4_ESCS['full'], codeBook = self.cb)\n",
    "        self._5_shouldBeCal['sliced'] = matching(self._4_ESCS['sliced'], codeBook = self.cb)\n",
    "\n",
    "    \n",
    "    def AdjustMinor(self):\n",
    "    # ```\n",
    "    # 마이너한 것들을 조정하기 위함\n",
    "    # ```\n",
    "        print('\\n\\n>>>> 7. Manually adjust')\n",
    "        # 두 데이터를 나라 row를 만들고, 합치기 위함\n",
    "        def Merge(inputData):\n",
    "            output = pd.concat([inputData['SK'], inputData['US']], axis=0)\n",
    "            assert inputData['SK'].shape[0] + inputData['US'].shape[0] == output.shape[0]\n",
    "\n",
    "            dropAcademic = ['CNTRYID', 'AcademicScore']\n",
    "            for column in output.columns:\n",
    "                if 'PV' in column:\n",
    "                    dropAcademic.append(column)\n",
    "\n",
    "            output.drop(dropAcademic, axis=1, inplace=True)\n",
    "            # print('>> columns: ', output.columns)\n",
    "            return output\n",
    "\n",
    "        # spss 편하도록, 주요 변수들을 앞으로 빼는 작업\n",
    "        def columnOrder(inputData,\n",
    "                        important_columns=['resilient']):\n",
    "            column_ID = ['CNT', 'CNTSCHID', 'CNTSTUID']\n",
    "\n",
    "            inputData.set_index(column_ID+important_columns, inplace=True)\n",
    "            inputData.reset_index(inplace=True)\n",
    "\n",
    "            return inputData\n",
    "\n",
    "        self.finalRS['full'] = Merge(self._5_shouldBeCal['full'])\n",
    "        self.finalRS['sliced'] = Merge(self._5_shouldBeCal['sliced'])\n",
    "\n",
    "        self.finalRS['full'] = columnOrder(self.finalRS['full'])\n",
    "        self.finalRS['sliced'] = columnOrder(self.finalRS['sliced'])\n",
    "\n",
    "\n",
    "processor = Preprocessing(LoadedData=loadedData, codeBook=Loader.cb, dummyCodeBook='dummyCoding.json')\n",
    "processor.noDataColumn()\n",
    "processor.Dummy(doDummy=False) # 굳이 dummy할 필요가 없음, rf에서 categorical / numerical 인식해야함\n",
    "processor.Join()\n",
    "processor.DropStudent()\n",
    "processor.ESCS(test_key='read_10')\n",
    "processor.shouldBeCalculated()\n",
    "processor.AdjustMinor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.ExcelWriter(os.path.join(BASE_DIR, 'data', 'preprocessing.xlsx')) as writer:\n",
    "    processor.finalRS['full'].to_excel(writer, sheet_name='full', index=False)\n",
    "    processor.finalRS['sliced'].to_excel(writer, sheet_name='sliced', index=False)\n",
    "\n",
    "with pd.ExcelWriter(os.path.join(BASE_DIR, 'data', 'raw_forValidate.xlsx')) as writer:\n",
    "    processor._3_dropNa['SK'].to_excel(writer, sheet_name='south korea', index=False)\n",
    "    processor._3_dropNa['US'].to_excel(writer, sheet_name='us', index=False)\n",
    "    processor._4_ESCS['sliced']['SK'].to_excel(writer, sheet_name='sliced', index=False)\n",
    "\n",
    "with pd.ExcelWriter(os.path.join(BASE_DIR, 'data', 'descriptive(raw).xlsx')) as writer:\n",
    "    processor.rs_1_columnFull.to_excel(writer, sheet_name='dsec_full', index=True)\n",
    "    processor.rs_1_columnSK.to_excel(writer, sheet_name='dsec_SK', index=True)\n",
    "    processor.rs_1_columnUS.to_excel(writer, sheet_name='dsec_US', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Descriptive Statics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 앞선 처리 데이터 불러오기\n",
    "fullData = pd.read_excel(os.path.join(BASE_DIR, 'data', 'preprocessing.xlsx'), sheet_name='full')\n",
    "# slicedData = pd.read_excel(os.path.join(BASE_DIR, 'data', 'preprocessing.xlsx'), sheet_name='sliced')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Descriptive:\n",
    "    def __init__(self, cleanedData):\n",
    "        self.df = cleanedData\n",
    "        self.NUM = {'full': pd.DataFrame(),\n",
    "                    'SK': {'SK': pd.DataFrame(), 'res': pd.DataFrame(), 'nonRes': pd.DataFrame()},\n",
    "                    'US': {'SK': pd.DataFrame(), 'res': pd.DataFrame(), 'nonRes': pd.DataFrame()}\n",
    "                    }\n",
    "        self.CAT = {'full': pd.DataFrame(),\n",
    "                    'SK': {'SK': pd.DataFrame(), 'res': pd.DataFrame(), 'nonRes': pd.DataFrame()},\n",
    "                    'US': {'SK': pd.DataFrame(), 'res': pd.DataFrame(), 'nonRes': pd.DataFrame()}\n",
    "                    }\n",
    "\n",
    "        self._1_full = pd.DataFrame()\n",
    "        self._2_SKFull = pd.DataFrame()\n",
    "        self._2_SKRes = pd.DataFrame()\n",
    "        self._2_SKnonRes = pd.DataFrame()\n",
    "        self._3_US = pd.DataFrame()\n",
    "        self._3_USRes = pd.DataFrame()\n",
    "        self._3_USnonRes = pd.DataFrame()\n",
    "        \n",
    "    def Numeric(self):\n",
    "\n",
    "        def naRatio(fullCount, inputArr):\n",
    "            output = 100 - inputArr/fullCount*100\n",
    "            return np.round(output, decimals=2)\n",
    "\n",
    "        def Full(inputData):\n",
    "            output = inputData.describe().T.round(2)\n",
    "            output['na_ratio'] = naRatio(inputData.shape[0], output['count'])\n",
    "            return output\n",
    "\n",
    "        def groupBy(inputData, groupByColumn):\n",
    "            output= {}\n",
    "            \n",
    "            for uniqueVal in inputData[groupByColumn].unique():\n",
    "                str_uniqueVal = str(uniqueVal) # in case of resilient, type changed\n",
    "                # print(str_uniqueVal)\n",
    "                df_slice = inputData[inputData[groupByColumn] == uniqueVal]\n",
    "                output[str_uniqueVal]= df_slice.describe().T.round(2)\n",
    "                output[str_uniqueVal]['na_ratio'] = naRatio(df_slice.shape[0], output[str_uniqueVal]['count'])\n",
    "                \n",
    "            return output\n",
    "\n",
    "        self.NUM['full'] = Full(self.df)\n",
    "\n",
    "        nationDict = groupBy(self.df, groupByColumn='CNT')\n",
    "        self.NUM['SK']['SK'] = nationDict['Korea']\n",
    "        self.NUM['US']['US'] = nationDict['United States']\n",
    "\n",
    "        resilientSK = groupBy(self.df[self.df['CNT'] == 'Korea'], groupByColumn='resilient')\n",
    "        self.NUM['SK']['res'] = resilientSK['1']\n",
    "        self.NUM['SK']['nonRes'] = resilientSK['0']\n",
    "        \n",
    "        resilientUS = groupBy(self.df[self.df['CNT'] == 'United States'], groupByColumn='resilient')\n",
    "        self.NUM['US']['res'] = resilientUS['1']\n",
    "        self.NUM['US']['nonRes'] = resilientUS['0']\n",
    "\n",
    "\n",
    "    def Categorical(self):\n",
    "\n",
    "        def sliceCategorical(inputData,\n",
    "                            referenceNumerical # for assert \n",
    "                            ):   \n",
    "            num_cols = inputData._get_numeric_data().columns\n",
    "            cat_cols = list(set(inputData.columns) - set(num_cols))\n",
    "            \n",
    "            assert list(num_cols) == list(referenceNumerical.index), print(num_cols)\n",
    "\n",
    "            return cat_cols\n",
    "\n",
    "        def Full(inputData, cat_cols):\n",
    "            df_cat = inputData[cat_cols]\n",
    "            temp = df_cat.describe(include='all').T\n",
    "            temp['na_ratio'] = temp['freq'].values/temp['count'].values*100\n",
    "            # temp['na_ratio'] = np.round(temp['na_ratio'], 2) #!# error: infinite\n",
    "            return temp\n",
    "            \n",
    "\n",
    "        def groupBy(inputData, groupByColumn, cat_cols):\n",
    "            output= {}\n",
    "            for uniqueVal in inputData[groupByColumn].unique():\n",
    "                str_uniqueVal = str(uniqueVal) # in case of resilient, type changed\n",
    "                df_slice = inputData[inputData[groupByColumn] == uniqueVal]\n",
    "                df_cat = df_slice[cat_cols] # slice\n",
    "                temp = df_cat.describe(include='all').T\n",
    "                \n",
    "                temp['na_ratio'] = 100 - temp['freq'].values/temp['count'].values*100\n",
    "                # temp['na_ratio'] = np.round(temp['na_ratio'], 2) #!# error: infinite\n",
    "                output[str_uniqueVal] = temp.round(2)\n",
    "                \n",
    "            return output\n",
    "\n",
    "        \n",
    "        cat_cols = sliceCategorical(self.df, referenceNumerical=self.NUM['full'])\n",
    "        self.CAT['full'] = Full(self.df, cat_cols=cat_cols)\n",
    "        \n",
    "        nationDict = groupBy(self.df, groupByColumn='CNT', cat_cols=cat_cols)\n",
    "        self.CAT['SK']['SK'] = nationDict['Korea']\n",
    "        self.CAT['US']['US'] = nationDict['United States']\n",
    "\n",
    "\n",
    "        resilientSK = groupBy(self.df[self.df['CNT'] == 'Korea'], groupByColumn='resilient', cat_cols=cat_cols)\n",
    "        self.CAT['SK']['res'] = resilientSK['1']\n",
    "        self.CAT['SK']['nonRes'] = resilientSK['0']\n",
    "        \n",
    "        resilientUS = groupBy(self.df[self.df['CNT'] == 'United States'], groupByColumn='resilient', cat_cols=cat_cols)\n",
    "        self.CAT['US']['res'] = resilientUS['1']\n",
    "        self.CAT['US']['nonRes'] = resilientUS['0']\n",
    "        \n",
    "    \n",
    "    def Join(self):\n",
    "\n",
    "        def merger(df_num, df_cat):\n",
    "            output = pd.concat([df_num, df_cat], axis=0) # concate on row\n",
    "            # for cat_idx in df_cat.index:\n",
    "            # 합치면 좋겠지만, num, cat 구분 잘되서 좋음\n",
    "\n",
    "            ## drop unnecessary columns\n",
    "            output.drop(columns=['min', '25%', '50%', '75%', 'max'], inplace=True)\n",
    "            output.drop(index=['CNTSCHID', 'CNTSTUID', 'CNT', 'resilient'], inplace=True)\n",
    "\n",
    "            ## re-order columns \n",
    "            output.reset_index(drop=False, inplace=True)\n",
    "            output.set_index(['index', 'count', 'na_ratio'], inplace=True)\n",
    "            output.reset_index(drop=False, inplace=True)\n",
    "            output.set_index('index',inplace=True)\n",
    "            return output.round(2)\n",
    "        \n",
    "        self._1_full = merger(self.NUM['full'], self.CAT['full'])\n",
    "        self._2_SKFull = merger(self.NUM['SK']['SK'], self.CAT['SK']['SK'])\n",
    "        self._2_SKRes = merger(self.NUM['SK']['res'], self.CAT['SK']['res'])\n",
    "        self._2_SKnonRes = merger(self.NUM['SK']['nonRes'], self.CAT['SK']['nonRes'])\n",
    "        self._3_USFull = merger(self.NUM['US']['US'], self.CAT['US']['US'])\n",
    "        self._3_USRes = merger(self.NUM['US']['res'], self.CAT['US']['res'])\n",
    "        self._3_USnonRes = merger(self.NUM['US']['nonRes'], self.CAT['US']['nonRes'])\n",
    "        \n",
    "        \n",
    "\n",
    "analyzer = Descriptive(fullData)\n",
    "analyzer.Numeric()\n",
    "analyzer.Categorical()\n",
    "analyzer.Join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.ExcelWriter(os.path.join(BASE_DIR, 'data', 'descriptive(cleaned).xlsx')) as writer:\n",
    "    analyzer._1_full.to_excel(writer, sheet_name='full', index=True)\n",
    "    analyzer._2_SKFull.to_excel(writer, sheet_name='Korea_f', index=True)\n",
    "    analyzer._2_SKRes.to_excel(writer, sheet_name='Korea_r', index=True)\n",
    "    analyzer._2_SKnonRes.to_excel(writer, sheet_name='Korea_nR', index=True)\n",
    "    analyzer._3_USFull.to_excel(writer, sheet_name='US_f', index=True)\n",
    "    analyzer._3_USRes.to_excel(writer, sheet_name='US_r', index=True)\n",
    "    analyzer._3_USnonRes.to_excel(writer, sheet_name='US_nR', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest\n",
    "- just for comparing results of random forest btw python and r"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('khrrc')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f2ed4711497f95c801e11ec0b21dd929a4a0de8689951f49fbf9abba32131afd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
