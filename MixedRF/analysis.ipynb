{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 학업탄력성 영향요인 연구\n",
    "@author: sjh\n",
    "\n",
    "## 1. Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Current OS:  win32\n",
      ">> Current WD:  c:\\Users\\snukh\\Proj\\Research\\MixedRF\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import copy\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "from sys import platform\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# unicode minus를 사용하지 않기 위한 설정 (minus 깨짐현상 방지)\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "plt.rcParams[\"figure.autolayout\"] = True\n",
    "\n",
    "# 설치된 폰트 출력\n",
    "import matplotlib.font_manager as fm\n",
    "font_list = [font.name for font in fm.fontManager.ttflist]\n",
    "plt.rcParams['font.family'] = 'Malgun Gothic'\n",
    "\n",
    "\n",
    "BASE_DIR = os.getcwd()\n",
    "print('>> Current OS: ', platform)\n",
    "print('>> Current WD: ', BASE_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Load:\n",
    "    def __init__(self, stuFolder, schFolder, tchFolder, codeBook,\n",
    "                onlyCodeBook, ):\n",
    "        if 'darwin' in platform:\n",
    "            self.BASE_DIR = '/Users/huni/Dropbox/[3]Project/[혼합효과 랜덤포레스트_2022]'\n",
    "        else:\n",
    "            if os.getlogin() == 'jhun1':\n",
    "                self.BASE_DIR = r'C:\\Users\\jhun1\\Dropbox\\[3]Project\\[혼합효과 랜덤포레스트_2022]'\n",
    "                \n",
    "            elif os.getlogin() == 'snukh':\n",
    "                self.BASE_DIR = r'C:\\Users\\snukh\\Downloads\\[혼합효과 랜덤포레스트_2022]' \n",
    "        rawData_Folder = 'PISA2018'\n",
    "        codebook_Folder = 'drive-download-20220816T053902Z-001'\n",
    "\n",
    "        if onlyCodeBook == False:\n",
    "            print('>>>>> Init: load raw data')\n",
    "            stuFile = [FILE for FILE in os.listdir(os.path.join(self.BASE_DIR, rawData_Folder, stuFolder)) if FILE[-4:] == '.sav'][0]\n",
    "            schFile = [FILE for FILE in os.listdir(os.path.join(self.BASE_DIR, rawData_Folder, schFolder)) if FILE[-4:] == '.sav'][0]\n",
    "            tchFile = [FILE for FILE in os.listdir(os.path.join(self.BASE_DIR, rawData_Folder, tchFolder)) if FILE[-4:] == '.sav'][0]\n",
    "\n",
    "            self.rawStu = pd.read_spss(os.path.join(self.BASE_DIR, rawData_Folder, stuFolder, stuFile))\n",
    "            self.rawSCH = pd.read_spss(os.path.join(self.BASE_DIR, rawData_Folder, schFolder, schFile))\n",
    "            self.rawTCH = pd.read_spss(os.path.join(self.BASE_DIR, rawData_Folder, tchFolder, tchFile))\n",
    "            self.dataLS = [self.rawStu, self.rawSCH, self.rawTCH]\n",
    "\n",
    "            # desciptive\n",
    "            print('>> Stu data set', self.rawStu.shape)\n",
    "            print('>> Sch data set', self.rawSCH.shape)\n",
    "            print('>> Tch data set', self.rawTCH.shape)\n",
    "        \n",
    "        else:\n",
    "            print('>> Only Codebook will be loaded')\n",
    "            pass\n",
    "        \n",
    "        self.cb = pd.read_excel(os.path.join(self.BASE_DIR, codebook_Folder, codeBook), sheet_name='변수선택(1213)')\n",
    "\n",
    "\n",
    "\n",
    "    def defaultCleaner(self):\n",
    "        print('\\n\\n>>>> Cleaning: default nation and variable')\n",
    "\n",
    "\n",
    "        ### dictionary by nation\n",
    "        def cleaningNational(dataLS, SouthKorea = 'Korea', US='United States'):\n",
    "            nationalData = {'SK': [], 'US': []}\n",
    "\n",
    "            for nation_name, code in zip(nationalData.keys(), [SouthKorea, US]):\n",
    "                print(f'\\n>> slicing: {nation_name}')\n",
    "                for data in dataLS:\n",
    "                    # print(data.head(5))\n",
    "                    temp2 = data[data['CNTRYID'] == code]\n",
    "                \n",
    "                    nationalData[nation_name].append(temp2)\n",
    "                    print('>> sliced shape: ', temp2.shape)\n",
    "            \n",
    "            return nationalData\n",
    "            \n",
    "\n",
    "        def cleaningVariable(data, codeBook):\n",
    "            output = {}\n",
    "            \n",
    "            for nation_name in data.keys():\n",
    "                Column_toSave = {'Stu': [], 'Sch': [], 'Tch': []}\n",
    "                for fileName, variable, category in tqdm(zip(codeBook['file name'].values, codeBook['NAME'].values, codeBook['categories']), desc=\">> variable check\"):\n",
    "                    # 코드북 내에서도 분석에서 제할 변수는 file name을 비움\n",
    "                    if type(fileName) != str:\n",
    "                        continue\n",
    "\n",
    "\n",
    "                    else: \n",
    "                        if category == 'identifier':\n",
    "                            Column_toSave['Stu'].append(variable)\n",
    "                            \n",
    "                            if variable == 'CNTSTUID':\n",
    "                                continue\n",
    "                            else: # 코드북 구조 문제: 학교, 교사 셋에는 해당 변수가 없어서 추가해줌\n",
    "                                Column_toSave['Sch'].append(variable)\n",
    "                                Column_toSave['Tch'].append(variable)\n",
    "\n",
    "                        else:\n",
    "                            if 'STU' in fileName:\n",
    "                                if variable in data[nation_name][0].columns:\n",
    "                                    Column_toSave['Stu'].append(variable)\n",
    "                                else:\n",
    "                                    print('>> none(stu)', variable)\n",
    "\n",
    "                            elif 'SCH' in fileName:\n",
    "                                if variable in data[nation_name][1].columns:\n",
    "                                    Column_toSave['Sch'].append(variable)\n",
    "                                else:\n",
    "                                    print('>> none(sch)', variable)\n",
    "\n",
    "                            elif 'TCH' in fileName:\n",
    "                                if variable in data[nation_name][2].columns:\n",
    "                                    Column_toSave['Tch'].append(variable)\n",
    "                                else:\n",
    "                                    print('>> none(tch)', variable)\n",
    "                    \n",
    "                \n",
    "                # print('>>>> save: ', Column_toSave)\n",
    "                output[nation_name] = [data[nation_name][0][Column_toSave['Stu']],\n",
    "                                        data[nation_name][1][Column_toSave['Sch']],\n",
    "                                        data[nation_name][2][Column_toSave['Tch']],\n",
    "                                        ]\n",
    "                assert len(Column_toSave['Tch']) < 4, print(Column_toSave['Tch'])\n",
    "\n",
    "            assert 'SK' in output.keys()\n",
    "            assert 'US' in output.keys()\n",
    "            return output\n",
    "\n",
    "        cleaned_Nation = cleaningNational(dataLS = self.dataLS)\n",
    "        self.default_cleaningData = cleaningVariable(data = cleaned_Nation, codeBook = self.cb)\n",
    "\n",
    "        # categories 에서 일단은 codebook에 있는 변수가 다 있나 확인\n",
    "        # categories 에서 individual & family, school 구분"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Only Codebook will be loaded\n"
     ]
    }
   ],
   "source": [
    "LOAD_ONLY_CODEBOOK = False\n",
    "\n",
    "Loader = Load(stuFolder=\"STU\", schFolder='SCH', tchFolder='TCH',\n",
    "                onlyCodeBook = LOAD_ONLY_CODEBOOK,\n",
    "                codeBook='PISA2018_CODEBOOK (변수선택-공유).xlsx'\n",
    "                )\n",
    "\n",
    "if LOAD_ONLY_CODEBOOK == False:\n",
    "    Loader.defaultCleaner()\n",
    "    print(Loader.default_cleaningData.keys())\n",
    "\n",
    "    with pd.ExcelWriter(os.path.join(BASE_DIR, 'data', 'cleanedData(SK).xlsx')) as writer:\n",
    "        Loader.default_cleaningData['SK'][0].to_excel(writer, sheet_name='stu', index=False)\n",
    "        Loader.default_cleaningData['SK'][1].to_excel(writer, sheet_name='sch', index=False)\n",
    "        Loader.default_cleaningData['SK'][2].to_excel(writer, sheet_name='tch', index=False) \n",
    "\n",
    "\n",
    "    with pd.ExcelWriter(os.path.join(BASE_DIR, 'data', 'cleanedData(US).xlsx')) as writer:\n",
    "        Loader.default_cleaningData['US'][0].to_excel(writer, sheet_name='stu', index=False)\n",
    "        Loader.default_cleaningData['US'][1].to_excel(writer, sheet_name='sch', index=False)\n",
    "        Loader.default_cleaningData['US'][2].to_excel(writer, sheet_name='tch', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "minor thing, for replicate hong kong paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>  (6037, 1119)\n",
      ">>  (152, 197)\n",
      ">>  (3754, 351)\n"
     ]
    }
   ],
   "source": [
    "# ls_hk = []\n",
    "# for data in Loader.dataLS:\n",
    "#     df = data[data['CNTRYID'] == 'Hong Kong']\n",
    "#     ls_hk.append(df)\n",
    "#     print('>> ', df.shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with pd.ExcelWriter(os.path.join(BASE_DIR, 'data', 'rawData(HK).xlsx')) as writer:\n",
    "#     ls_hk[0].to_excel(writer, sheet_name='stu', index=False)\n",
    "#     ls_hk[1].to_excel(writer, sheet_name='sch', index=False)\n",
    "#     ls_hk[2].to_excel(writer, sheet_name='tch', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 앞선 처리 데이터 불러오기\n",
    "loadedData = {'SK': [\n",
    "            pd.read_excel(os.path.join(BASE_DIR,'data', 'cleanedData(SK).xlsx'), sheet_name='stu'),\n",
    "            pd.read_excel(os.path.join(BASE_DIR,'data', 'cleanedData(SK).xlsx'), sheet_name='sch'),\n",
    "            pd.read_excel(os.path.join(BASE_DIR,'data', 'cleanedData(SK).xlsx'), sheet_name='tch'),\n",
    "            \n",
    "            ],\n",
    "        'US': [\n",
    "            pd.read_excel(os.path.join(BASE_DIR,'data', 'cleanedData(US).xlsx'), sheet_name='stu'),\n",
    "            pd.read_excel(os.path.join(BASE_DIR,'data', 'cleanedData(US).xlsx'), sheet_name='sch'),\n",
    "            pd.read_excel(os.path.join(BASE_DIR,'data', 'cleanedData(US).xlsx'), sheet_name='tch'),\n",
    "            ]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loadedData['']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> test NA column:  SK\n",
      "stu\n",
      "sch\n",
      ">> test NA column:  US\n",
      "stu\n",
      ">>> over 80% is NA:  PERSPECT\n",
      "sch\n",
      "\n",
      "\n",
      ">>>> 1. Dummy coding\n",
      "\n",
      "\n",
      ">>>> 2. Join DataFrame\n",
      ">> join nation:  SK\n",
      ">> school data is empty\n",
      ">> join nation:  US\n",
      ">> school data is empty\n",
      "\n",
      "\n",
      ">>>> 3. Verify na and Drop student\n",
      "dict_keys(['SK', 'US'])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1224x432 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> NA drop:  44\n",
      ">> NA drop:  196\n",
      "\n",
      "\n",
      ">>>> 4. Slicing data by ESCS\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"None of [Index(['PV1READ', 'PV2READ', 'PV3READ', 'PV4READ', 'PV5READ', 'PV6READ',\\n       'PV7READ', 'PV8READ', 'PV9READ', 'PV10READ'],\\n      dtype='object')] are in the [columns]\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\jhun1\\Proj\\Research\\MixedRF\\analysis.ipynb Cell 13\u001b[0m in \u001b[0;36m<cell line: 465>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/jhun1/Proj/Research/MixedRF/analysis.ipynb#X45sZmlsZQ%3D%3D?line=462'>463</a>\u001b[0m processor\u001b[39m.\u001b[39mJoin()\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/jhun1/Proj/Research/MixedRF/analysis.ipynb#X45sZmlsZQ%3D%3D?line=463'>464</a>\u001b[0m processor\u001b[39m.\u001b[39mDropStudent()\n\u001b[1;32m--> <a href='vscode-notebook-cell:/c%3A/Users/jhun1/Proj/Research/MixedRF/analysis.ipynb#X45sZmlsZQ%3D%3D?line=464'>465</a>\u001b[0m processor\u001b[39m.\u001b[39;49mESCS(test_key\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mread_10\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/jhun1/Proj/Research/MixedRF/analysis.ipynb#X45sZmlsZQ%3D%3D?line=465'>466</a>\u001b[0m processor\u001b[39m.\u001b[39mshouldBeCalculated()\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/jhun1/Proj/Research/MixedRF/analysis.ipynb#X45sZmlsZQ%3D%3D?line=466'>467</a>\u001b[0m processor\u001b[39m.\u001b[39mAdjustMinor()\n",
      "\u001b[1;32mc:\\Users\\jhun1\\Proj\\Research\\MixedRF\\analysis.ipynb Cell 13\u001b[0m in \u001b[0;36mPreprocessing.ESCS\u001b[1;34m(self, test_key)\u001b[0m\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/jhun1/Proj/Research/MixedRF/analysis.ipynb#X45sZmlsZQ%3D%3D?line=323'>324</a>\u001b[0m     plt\u001b[39m.\u001b[39mshow()\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/jhun1/Proj/Research/MixedRF/analysis.ipynb#X45sZmlsZQ%3D%3D?line=325'>326</a>\u001b[0m \u001b[39m## 1. calculate threshold value\u001b[39;00m\n\u001b[1;32m--> <a href='vscode-notebook-cell:/c%3A/Users/jhun1/Proj/Research/MixedRF/analysis.ipynb#X45sZmlsZQ%3D%3D?line=326'>327</a>\u001b[0m AcademicThreshold, newData_dict \u001b[39m=\u001b[39m thresholdCalculator(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_3_dropNa,\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/jhun1/Proj/Research/MixedRF/analysis.ipynb#X45sZmlsZQ%3D%3D?line=327'>328</a>\u001b[0m                                                     test_key\u001b[39m=\u001b[39;49mtest_key) \u001b[39m## 학업성취 코딩 방법을 바꿀 때 여기 arg를 조정\u001b[39;00m\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/jhun1/Proj/Research/MixedRF/analysis.ipynb#X45sZmlsZQ%3D%3D?line=328'>329</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m>> 학문성취 상위 75%: 우리나라.. \u001b[39m\u001b[39m{\u001b[39;00mAcademicThreshold[\u001b[39m'\u001b[39m\u001b[39mSK\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m'\u001b[39m\u001b[39macademic_score\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m}\u001b[39;00m\u001b[39m, 미국.. \u001b[39m\u001b[39m{\u001b[39;00mAcademicThreshold[\u001b[39m'\u001b[39m\u001b[39mUS\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m'\u001b[39m\u001b[39macademic_score\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/jhun1/Proj/Research/MixedRF/analysis.ipynb#X45sZmlsZQ%3D%3D?line=331'>332</a>\u001b[0m \u001b[39m## 2. slice\u001b[39;00m\n",
      "\u001b[1;32mc:\\Users\\jhun1\\Proj\\Research\\MixedRF\\analysis.ipynb Cell 13\u001b[0m in \u001b[0;36mPreprocessing.ESCS.<locals>.thresholdCalculator\u001b[1;34m(inputData, test_key)\u001b[0m\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/jhun1/Proj/Research/MixedRF/analysis.ipynb#X45sZmlsZQ%3D%3D?line=231'>232</a>\u001b[0m targetColumn \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtestBook[test_key]\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/jhun1/Proj/Research/MixedRF/analysis.ipynb#X45sZmlsZQ%3D%3D?line=232'>233</a>\u001b[0m \u001b[39mfor\u001b[39;00m nationalName, inputNational \u001b[39min\u001b[39;00m inputData\u001b[39m.\u001b[39mitems():\n\u001b[1;32m--> <a href='vscode-notebook-cell:/c%3A/Users/jhun1/Proj/Research/MixedRF/analysis.ipynb#X45sZmlsZQ%3D%3D?line=233'>234</a>\u001b[0m     inputNational[\u001b[39m'\u001b[39m\u001b[39mAcademicScore\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m inputNational\u001b[39m.\u001b[39;49mloc[:, targetColumn]\u001b[39m.\u001b[39mmean(axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/jhun1/Proj/Research/MixedRF/analysis.ipynb#X45sZmlsZQ%3D%3D?line=234'>235</a>\u001b[0m     \u001b[39m# threshold[nationalName]['academic_score'] = inputNational['AcademicScore'].quantile(0.75)\u001b[39;00m\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/jhun1/Proj/Research/MixedRF/analysis.ipynb#X45sZmlsZQ%3D%3D?line=235'>236</a>\u001b[0m     threshold[nationalName][\u001b[39m'\u001b[39m\u001b[39macademic_score\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m \u001b[39m563\u001b[39m \u001b[39m#!# 수동으로 조정해줘야 함\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\jhun1\\anaconda3\\envs\\khrrc\\lib\\site-packages\\pandas\\core\\indexing.py:961\u001b[0m, in \u001b[0;36m_LocationIndexer.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    959\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_is_scalar_access(key):\n\u001b[0;32m    960\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj\u001b[39m.\u001b[39m_get_value(\u001b[39m*\u001b[39mkey, takeable\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_takeable)\n\u001b[1;32m--> 961\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_getitem_tuple(key)\n\u001b[0;32m    962\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    963\u001b[0m     \u001b[39m# we by definition only have the 0th axis\u001b[39;00m\n\u001b[0;32m    964\u001b[0m     axis \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maxis \u001b[39mor\u001b[39;00m \u001b[39m0\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\jhun1\\anaconda3\\envs\\khrrc\\lib\\site-packages\\pandas\\core\\indexing.py:1149\u001b[0m, in \u001b[0;36m_LocIndexer._getitem_tuple\u001b[1;34m(self, tup)\u001b[0m\n\u001b[0;32m   1146\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_multi_take_opportunity(tup):\n\u001b[0;32m   1147\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_multi_take(tup)\n\u001b[1;32m-> 1149\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_getitem_tuple_same_dim(tup)\n",
      "File \u001b[1;32mc:\\Users\\jhun1\\anaconda3\\envs\\khrrc\\lib\\site-packages\\pandas\\core\\indexing.py:827\u001b[0m, in \u001b[0;36m_LocationIndexer._getitem_tuple_same_dim\u001b[1;34m(self, tup)\u001b[0m\n\u001b[0;32m    824\u001b[0m \u001b[39mif\u001b[39;00m com\u001b[39m.\u001b[39mis_null_slice(key):\n\u001b[0;32m    825\u001b[0m     \u001b[39mcontinue\u001b[39;00m\n\u001b[1;32m--> 827\u001b[0m retval \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39;49m(retval, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mname)\u001b[39m.\u001b[39;49m_getitem_axis(key, axis\u001b[39m=\u001b[39;49mi)\n\u001b[0;32m    828\u001b[0m \u001b[39m# We should never have retval.ndim < self.ndim, as that should\u001b[39;00m\n\u001b[0;32m    829\u001b[0m \u001b[39m#  be handled by the _getitem_lowerdim call above.\u001b[39;00m\n\u001b[0;32m    830\u001b[0m \u001b[39massert\u001b[39;00m retval\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mndim\n",
      "File \u001b[1;32mc:\\Users\\jhun1\\anaconda3\\envs\\khrrc\\lib\\site-packages\\pandas\\core\\indexing.py:1191\u001b[0m, in \u001b[0;36m_LocIndexer._getitem_axis\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1188\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(key, \u001b[39m\"\u001b[39m\u001b[39mndim\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mand\u001b[39;00m key\u001b[39m.\u001b[39mndim \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m   1189\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mCannot index with multidimensional key\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m-> 1191\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_getitem_iterable(key, axis\u001b[39m=\u001b[39;49maxis)\n\u001b[0;32m   1193\u001b[0m \u001b[39m# nested tuple slicing\u001b[39;00m\n\u001b[0;32m   1194\u001b[0m \u001b[39mif\u001b[39;00m is_nested_tuple(key, labels):\n",
      "File \u001b[1;32mc:\\Users\\jhun1\\anaconda3\\envs\\khrrc\\lib\\site-packages\\pandas\\core\\indexing.py:1132\u001b[0m, in \u001b[0;36m_LocIndexer._getitem_iterable\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1129\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_key(key, axis)\n\u001b[0;32m   1131\u001b[0m \u001b[39m# A collection of keys\u001b[39;00m\n\u001b[1;32m-> 1132\u001b[0m keyarr, indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_listlike_indexer(key, axis)\n\u001b[0;32m   1133\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj\u001b[39m.\u001b[39m_reindex_with_indexers(\n\u001b[0;32m   1134\u001b[0m     {axis: [keyarr, indexer]}, copy\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, allow_dups\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m\n\u001b[0;32m   1135\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\jhun1\\anaconda3\\envs\\khrrc\\lib\\site-packages\\pandas\\core\\indexing.py:1327\u001b[0m, in \u001b[0;36m_LocIndexer._get_listlike_indexer\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1324\u001b[0m ax \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj\u001b[39m.\u001b[39m_get_axis(axis)\n\u001b[0;32m   1325\u001b[0m axis_name \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj\u001b[39m.\u001b[39m_get_axis_name(axis)\n\u001b[1;32m-> 1327\u001b[0m keyarr, indexer \u001b[39m=\u001b[39m ax\u001b[39m.\u001b[39;49m_get_indexer_strict(key, axis_name)\n\u001b[0;32m   1329\u001b[0m \u001b[39mreturn\u001b[39;00m keyarr, indexer\n",
      "File \u001b[1;32mc:\\Users\\jhun1\\anaconda3\\envs\\khrrc\\lib\\site-packages\\pandas\\core\\indexes\\base.py:5782\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[1;34m(self, key, axis_name)\u001b[0m\n\u001b[0;32m   5779\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   5780\u001b[0m     keyarr, indexer, new_indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[1;32m-> 5782\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_raise_if_missing(keyarr, indexer, axis_name)\n\u001b[0;32m   5784\u001b[0m keyarr \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtake(indexer)\n\u001b[0;32m   5785\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(key, Index):\n\u001b[0;32m   5786\u001b[0m     \u001b[39m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\jhun1\\anaconda3\\envs\\khrrc\\lib\\site-packages\\pandas\\core\\indexes\\base.py:5842\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[1;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[0;32m   5840\u001b[0m     \u001b[39mif\u001b[39;00m use_interval_msg:\n\u001b[0;32m   5841\u001b[0m         key \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(key)\n\u001b[1;32m-> 5842\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mNone of [\u001b[39m\u001b[39m{\u001b[39;00mkey\u001b[39m}\u001b[39;00m\u001b[39m] are in the [\u001b[39m\u001b[39m{\u001b[39;00maxis_name\u001b[39m}\u001b[39;00m\u001b[39m]\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   5844\u001b[0m not_found \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[39m.\u001b[39mnonzero()[\u001b[39m0\u001b[39m]]\u001b[39m.\u001b[39munique())\n\u001b[0;32m   5845\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mnot_found\u001b[39m}\u001b[39;00m\u001b[39m not in index\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"None of [Index(['PV1READ', 'PV2READ', 'PV3READ', 'PV4READ', 'PV5READ', 'PV6READ',\\n       'PV7READ', 'PV8READ', 'PV9READ', 'PV10READ'],\\n      dtype='object')] are in the [columns]\""
     ]
    }
   ],
   "source": [
    "class Preprocessing:\n",
    "    def __init__(self, LoadedData, codeBook, dummyCodeBook):\n",
    "        self.data = LoadedData\n",
    "        self.cb = codeBook\n",
    "        with open(dummyCodeBook, encoding='utf-8') as json_file:\n",
    "            self.dummyCB = json.load(json_file)\n",
    "        self.testBook = {\n",
    "                    'read/math/sci_1': 'PV1MATH PV1READ PV1SCIE'.split(),\n",
    "                    'read/math_1': 'PV1MATH PV1READ'.split(),\n",
    "                    'read/math_10': 'PV1MATH PV2MATH PV3MATH PV4MATH PV5MATH PV6MATH PV7MATH PV8MATH PV9MATH PV10MATH PV1READ PV2READ PV3READ PV4READ PV5READ PV6READ PV7READ PV8READ PV9READ PV10READ'.split(),\n",
    "                    'read_1': ['PV1READ'],\n",
    "                    'read_10': 'PV1READ PV2READ PV3READ PV4READ PV5READ PV6READ PV7READ PV8READ PV9READ PV10READ'.split()\n",
    "                }\n",
    "\n",
    "        self._1_dummy = {}\n",
    "        self._2_joined = {}\n",
    "        self._3_dropNa = {}\n",
    "        self._4_ESCS = {'full': {}, 'sliced': {}} # 여기서 데이터 갈라야함\n",
    "        self._5_shouldBeCal = {}\n",
    "        self.finalRS = {}\n",
    "        \n",
    "        self.rs_1_columnFull = pd.DataFrame()\n",
    "        self.rs_1_columnSK = pd.DataFrame()\n",
    "        self.rs_1_columnUS = pd.DataFrame()\n",
    "        \n",
    "\n",
    "    ### Needs1. is selected variable contained in both dataset\n",
    "    def noDataColumn(self): # 열별로 계산\n",
    "        toDrop = {}\n",
    "        \n",
    "        for nationName, nationalData in self.data.items():\n",
    "            print('>> test NA column: ', nationName)\n",
    "\n",
    "            toDrop[nationName] = []\n",
    "            for idx, (label, inputDf) in enumerate(zip('stu sch tch'.split(), nationalData)):\n",
    "                if label == 'tch':\n",
    "                    continue\n",
    "                else:\n",
    "                    print(label)\n",
    "                    for column in inputDf.columns:\n",
    "                        if inputDf[column].isna().sum() > (inputDf.shape[0] * 0.8):\n",
    "                            print('>>> over 80% is NA: ', column)\n",
    "                            toDrop[nationName].append(column)\n",
    "                        \n",
    "                        elif 'missing' in inputDf[column].values:\n",
    "                            print('>>> missing: ', column)\n",
    "                            toDrop[nationName].append(column)\n",
    "                        \n",
    "                        else:\n",
    "                            continue\n",
    "        return toDrop\n",
    "            # assert len(toDrop[nationName]) == 2, print(toDrop)\n",
    "\n",
    "\n",
    "    def Dummy(self, doDummy):\n",
    "        # match key and value from codeBook\n",
    "        print('\\n\\n>>>> 1. Dummy coding')\n",
    "        def matchKV(codeBookDict, inputList):\n",
    "            outputLS = []\n",
    "            for val in inputList:\n",
    "                try:\n",
    "                    outputLS.append(codeBookDict[val])\n",
    "                except KeyError:\n",
    "                    outputLS.append(np.nan)\n",
    "            \n",
    "            return outputLS\n",
    "        \n",
    "        if doDummy == True:\n",
    "            notDummyCol1 = self.cb[self.cb['categories'] == 'identifier'].index\n",
    "            notDummyCol2 = self.cb[self.cb['categories'] == 'resilient status'].index\n",
    "            notDummyCol3 = self.cb[self.cb['file name'] == 'should be caculated'].index\n",
    "            \n",
    "            toDummy = self.cb.drop(list(notDummyCol1)+list(notDummyCol2)+list(notDummyCol3), axis=0) # 더미 변환 안할 변수 행 삭제함\n",
    "            # display(toDummy)\n",
    "\n",
    "            for nationalName, inputNational in self.data.items():\n",
    "                outputNational = copy.deepcopy(inputNational)\n",
    "\n",
    "                for idx, row in toDummy.iterrows(): # 변수별로 반복문\n",
    "                    variable = row['NAME']\n",
    "                    \n",
    "                    if type(row['file name']) != str: # 분석에서 제외할 변수가 있어서 버림\n",
    "                        continue\n",
    "\n",
    "                    else:\n",
    "                        if ('STU' in row['file name']) and (variable in self.dummyCB['stu']):\n",
    "                            outputLS = matchKV(self.dummyCB['stu'][variable], outputNational[0][variable])\n",
    "                            outputNational[0][variable] = outputLS \n",
    "\n",
    "                    # 학교, 교사 데이터는 더미코딩할 것 없음\n",
    "                self._1_dummy[nationalName] = outputNational\n",
    "        elif doDummy == False:\n",
    "            self._1_dummy = copy.deepcopy(self.data)\n",
    "        else:\n",
    "            raise TypeError('>> Error: check option Type')\n",
    "\n",
    "\n",
    "    def Join(self):\n",
    "        print('\\n\\n>>>> 2. Join DataFrame')\n",
    "\n",
    "        for nationalName, inputNational in self._1_dummy.items():\n",
    "            print('>> join nation: ', nationalName)\n",
    "            inputNational[0].reset_index(drop=True, inplace=True)\n",
    "            \n",
    "            outputDf = copy.deepcopy(inputNational[0])\n",
    "            # print('>> before ', outputDf.shape)\n",
    "            before = outputDf.shape\n",
    "\n",
    "\n",
    "            inputNational[1].drop(['CNTRYID', 'CNT'], axis=1, inplace=True)\n",
    "            if inputNational[1].index.name == 'CNTSCHID':\n",
    "                pass\n",
    "            else:\n",
    "                inputNational[1].set_index('CNTSCHID', drop=True, inplace=True)\n",
    "            \n",
    "            if inputNational[1].shape[1] == 0:\n",
    "                print('>> school data is empty')\n",
    "                pass\n",
    "            else:\n",
    "                for idx, row in tqdm(outputDf.iterrows(), desc=\">> mapping\"):\n",
    "                    toBeInput = inputNational[1].loc[row['CNTSCHID']].values # 학생 데이터에 들어가야할 학교 데이터 찾기\n",
    "                    assert len(toBeInput) == inputNational[1].shape[1]\n",
    "                    \n",
    "                    toBeInput_T = toBeInput.reshape(1, 8)\n",
    "                    outputDf.loc[idx, list(inputNational[1].columns)] = toBeInput_T[0]\n",
    "            \n",
    "                after = outputDf.shape\n",
    "                print('>>>> Bef: ', before, '....', 'Aft: ', after)\n",
    "                assert 'EDUSHORT' in outputDf.columns\n",
    "\n",
    "            self._2_joined[nationalName] = outputDf\n",
    "\n",
    "    def DropStudent(self):\n",
    "        # 각 column 별로 데이터 검수\n",
    "        print('\\n\\n>>>> 3. Verify na and Drop student')\n",
    "        print(self._2_joined.keys())\n",
    "        def column_wise(inputData):\n",
    "            if type(inputData) == dict:\n",
    "                merged = pd.concat([inputData['SK'], inputData['US']])\n",
    "                assert merged.shape[0] == inputData['SK'].shape[0] + inputData['US'].shape[0]\n",
    "            elif type(inputData) == pd.DataFrame:\n",
    "                merged = copy.deepcopy(inputData)\n",
    "            \n",
    "            else:\n",
    "                raise TypeError('>> Error: Check your input D type')\n",
    "                \n",
    "\n",
    "            describeDF = merged.describe().T\n",
    "            describeDF['NA_ratio'] = round(\n",
    "                100 - describeDF['count']/merged.shape[0]*100,\n",
    "                 2\n",
    "                 )\n",
    "\n",
    "            newColumnOrder = [describeDF.columns[0], 'NA_ratio'] + list(describeDF.columns[1:-1])\n",
    "            describeDF= describeDF[newColumnOrder]\n",
    "            return describeDF\n",
    "\n",
    "        # 각 학생별로 데이터 검수\n",
    "        def row_wise(inputData):\n",
    "            merged = pd.concat([inputData['SK'], inputData['US']])\n",
    "            assert merged.shape[0] == inputData['SK'].shape[0] + inputData['US'].shape[0]\n",
    "            # unlike column wise, we prepare data with \n",
    "\n",
    "            for_histogram = {}\n",
    "            for label, data in zip(['full', 'SK', 'US'], [merged, inputData['SK'], inputData['US']]):\n",
    "                for_histogram[label] = []\n",
    "\n",
    "                for i in range(len(data.index)) :\n",
    "                    na_ratio = round((data.iloc[i].isnull().sum()/data.shape[1]) * 100, 0)\n",
    "                    for_histogram[label].append(na_ratio)\n",
    "\n",
    "            fig = plt.figure(figsize=(17,6))\n",
    "\n",
    "            plt.subplot(1, 3, 1)\n",
    "            plt.hist(for_histogram['full'])\n",
    "            plt.title('\\n전체 데이터\\n')\n",
    "            plt.xlabel('\\n전체 변수 대비 결측비율(%)\\n')\n",
    "            plt.ylabel('빈도')\n",
    "            \n",
    "            plt.subplot(1, 3, 2)\n",
    "            plt.hist(for_histogram['SK'])\n",
    "            plt.title('\\nSouth Korea\\n')\n",
    "            plt.xlabel('\\n전체 변수 대비 결측비율(%)\\n')\n",
    "            plt.ylabel('빈도')\n",
    "            \n",
    "            plt.subplot(1, 3, 3)\n",
    "            plt.hist(for_histogram['US'])\n",
    "            plt.title('\\nUnited States\\n')\n",
    "            plt.xlabel('\\n전체 변수 대비 결측비율(%)\\n')\n",
    "            plt.ylabel('빈도')\n",
    "\n",
    "            plt.savefig(os.path.join(BASE_DIR, 'data', f'NA_ratio.jpg'))\n",
    "            plt.show()\n",
    "\n",
    "            return for_histogram\n",
    "        \n",
    "        def dropOver(inputData, rowWiseResult):\n",
    "            assert type(rowWiseResult) == list\n",
    "            output = copy.deepcopy(inputData)\n",
    "\n",
    "            toDrop = []\n",
    "            for idx, sumNA in zip(output.index, rowWiseResult):\n",
    "                if sumNA > 30:\n",
    "                    toDrop.append(idx)\n",
    "            \n",
    "            before = output.shape[0]\n",
    "            output.drop(toDrop, axis=0, inplace=True)\n",
    "            after = output.shape[0]\n",
    "            print('>> NA drop: ', before - after)\n",
    "\n",
    "            return output\n",
    "        \n",
    "        self.rs_1_columnFull = column_wise(self._2_joined)\n",
    "        self.rs_1_columnSK = column_wise(self._2_joined['SK'])\n",
    "        self.rs_1_columnUS = column_wise(self._2_joined['US'])\n",
    "\n",
    "        rowWiseNA = row_wise(self._2_joined)\n",
    "        self._3_dropNa['SK'] = dropOver(self._2_joined['SK'], rowWiseResult=rowWiseNA['SK'])\n",
    "        self._3_dropNa['US'] = dropOver(self._2_joined['US'], rowWiseResult=rowWiseNA['US'])\n",
    "        \n",
    "        \n",
    "    def ESCS(self, test_key):\n",
    "        # 데이터를 두개 만들어야함, result, resultSlice\n",
    "        print('\\n\\n>>>> 4. Slicing data by ESCS')\n",
    "        \n",
    "        def thresholdCalculator(inputData,\n",
    "                                test_key # 시험해볼 열\n",
    "                                ):\n",
    "            \n",
    "            threshold = {'SK': {}, 'US': {}}\n",
    "\n",
    "            targetColumn = self.testBook[test_key]\n",
    "            for nationalName, inputNational in inputData.items():\n",
    "                inputNational['AcademicScore'] = inputNational.loc[:, targetColumn].mean(axis=1)\n",
    "                # threshold[nationalName]['academic_score'] = inputNational['AcademicScore'].quantile(0.75)\n",
    "                threshold[nationalName]['academic_score'] = 563 #!# 수동으로 조정해줘야 함\n",
    "                threshold[nationalName]['escs_score'] = inputNational['ESCS'].quantile(0.25)\n",
    "\n",
    "            return threshold, inputData # 새로운 열이 추가되었으므로 리턴해서 사용해야함\n",
    "        \n",
    "        def escsSlice(inputDict, escsThreshold):\n",
    "            assert type(inputDict) == dict, print('>> Error: must input Dict')\n",
    "            assert type(escsThreshold) == dict\n",
    "            output = {'SK': pd.DataFrame(), 'US': pd.DataFrame()}\n",
    "            for nationalName, inputNational in inputDict.items():\n",
    "                \n",
    "                before = inputNational.shape[0]\n",
    "                toDrop = []\n",
    "                for idx, val in zip(inputNational['ESCS'].index, inputNational['ESCS'].values):\n",
    "                    if val < escsThreshold[nationalName]['escs_score']:\n",
    "                        continue\n",
    "                    else:\n",
    "                        toDrop.append(idx) # escs 하위 25%를 넘는 친구들은 버림\n",
    "                \n",
    "                \n",
    "                output[nationalName] = inputNational.drop(toDrop, axis=0)\n",
    "                after = output[nationalName].shape[0]\n",
    "                print('>> before: ', before, '>> after: ', after)\n",
    "            \n",
    "            return output\n",
    "\n",
    "\n",
    "        def quantileCalculator( \n",
    "                            inputData, # 전체 Full, escs 하위 25%로 데이터셋이 2개로 나뉘므로 인풋을 줘야함\n",
    "                            option, # full: 전체 데이터, sliced: 잘린 데이터\n",
    "                            AcademicThreshold\n",
    "                            ):\n",
    "            \n",
    "            assert type(AcademicThreshold) == dict\n",
    "            print('\\n>> Option: ', option)\n",
    "\n",
    "            output = {'SK': pd.DataFrame(), 'US': pd.DataFrame()}\n",
    "            for IDX, (nationalName, inputNational) in enumerate(inputData.items()):\n",
    "                total = inputNational.shape[0]\n",
    "                \n",
    "                iamResilient = []\n",
    "                if option == 'full':\n",
    "                    escsVar = inputNational['ESCS'].quantile(0.25) # 하위 25%\n",
    "                    for idx, row in inputNational.iterrows():\n",
    "                        if row['AcademicScore'] > AcademicThreshold[nationalName]['academic_score'] and row['ESCS'] < AcademicThreshold[nationalName]['escs_score']: # sliced 데이터에서는 이 기준을 만족할 수 없음\n",
    "                            iamResilient.append(1)\n",
    "                        else:\n",
    "                            iamResilient.append(0)\n",
    "\n",
    "                elif option == 'sliced':\n",
    "                    for idx, row in inputNational.iterrows():\n",
    "                        if row['AcademicScore'] > AcademicThreshold[nationalName]['academic_score']: # sliced 데이터는 escs 기준 필요 없음\n",
    "                            iamResilient.append(1)\n",
    "                        else:\n",
    "                            iamResilient.append(0)\n",
    "\n",
    "                inputNational['resilient'] = iamResilient\n",
    "                resilientCount = [x for x in iamResilient if x ==1]\n",
    "                print(f'>> 회복탄력성 학생수({nationalName}): ', len(resilientCount), f'({round(len(resilientCount)/total*100, 2)})%')\n",
    "\n",
    "                output[nationalName] = inputNational\n",
    "\n",
    "            return output\n",
    "\n",
    "        def visualize(inputData,\n",
    "                    option, # full: 전체 데이터, sliced: 잘린 데이터\n",
    "                    figName, # 그림 제목\n",
    "                    AcademicThreshold\n",
    "                        ):\n",
    "\n",
    "            fig = plt.figure(figsize=(17,9))\n",
    "            for IDX, (nationalName, inputNational) in enumerate(inputData.items()):\n",
    "\n",
    "                plt.subplot(2, 2, 2*IDX+1)\n",
    "                plt.hist(inputNational['AcademicScore'])\n",
    "                plt.title(f'\\n학업성취{nationalName}\\n')\n",
    "                plt.xlabel('\\n점수\\n')\n",
    "                plt.axvline(AcademicThreshold[nationalName]['academic_score'], color='r', linewidth=1, linestyle='--')\n",
    "                \n",
    "                plt.subplot(2, 2, 2*IDX+2)\n",
    "                plt.hist(inputNational['ESCS'])\n",
    "                plt.title(f'\\n사회문화경제{nationalName}\\n')\n",
    "                plt.xlabel('\\n점수\\n')\n",
    "                if option=='full':\n",
    "                    plt.axvline(AcademicThreshold[nationalName]['escs_score'], color='r', linewidth=1, linestyle='--')\n",
    "\n",
    "                \n",
    "            plt.savefig(os.path.join(BASE_DIR, 'data', f'{figName}_{option}.jpg'))\n",
    "            plt.show()\n",
    "        \n",
    "        ## 1. calculate threshold value\n",
    "        AcademicThreshold, newData_dict = thresholdCalculator(self._3_dropNa,\n",
    "                                                            test_key=test_key) ## 학업성취 코딩 방법을 바꿀 때 여기 arg를 조정\n",
    "        print(f\">> 학문성취 상위 75%: 우리나라.. {AcademicThreshold['SK']['academic_score']}, 미국.. {AcademicThreshold['US']['academic_score']}\")\n",
    "        \n",
    "        \n",
    "        ## 2. slice\n",
    "        self._4_ESCS['full'] = copy.deepcopy(newData_dict) # no drop case, so just copied\n",
    "        self._4_ESCS['sliced'] = escsSlice(newData_dict, escsThreshold = AcademicThreshold)\n",
    "        assert type(self._4_ESCS['full']) == dict, print(self._4_ESCS['full'])\n",
    "\n",
    "\n",
    "        ## 3. labeling resilient student\n",
    "        self._4_ESCS['full'] = quantileCalculator(inputData=self._4_ESCS['full'], \n",
    "                                                option = 'full',\n",
    "                                                AcademicThreshold= AcademicThreshold)\n",
    "        self._4_ESCS['sliced'] = quantileCalculator(inputData=self._4_ESCS['sliced'], \n",
    "                                                option = 'sliced',\n",
    "                                                AcademicThreshold= AcademicThreshold)\n",
    "\n",
    "        ## 4. visualize resilient student\n",
    "        visualize(self._4_ESCS['full'], option='full', figName='읽10', AcademicThreshold= AcademicThreshold)\n",
    "        visualize(self._4_ESCS['sliced'], option = 'sliced', figName ='읽10(target paper)', AcademicThreshold= AcademicThreshold)\n",
    "\n",
    "    \n",
    "    # should be calculated 변수들 계산하는 것임\n",
    "    def shouldBeCalculated(self):\n",
    "        print('\\n\\n>>>> 6. Should Be Calculated')\n",
    "        \n",
    "        def schoolMean(inputDf, whichVar):\n",
    "            assert type(whichVar) == list\n",
    "            outputMean = {}\n",
    "            for sch_id in inputDf['CNTSCHID'].values:\n",
    "                # print('>> ', sch_id)\n",
    "                if sch_id in outputMean.keys():\n",
    "                    continue\n",
    "                \n",
    "                else:\n",
    "                    temp1 = inputDf[inputDf['CNTSCHID'] == sch_id]\n",
    "                    temp2 = temp1.loc[:, whichVar] \n",
    "                    assert len(temp2.columns) == len(whichVar)\n",
    "                    meanVal = np.nanmean(temp2.values)\n",
    "                    assert type(meanVal) == np.float64, print('Error : ', type(meanVal))\n",
    "\n",
    "                    outputMean[sch_id] = meanVal\n",
    "            \n",
    "            return outputMean\n",
    "        \n",
    "        \n",
    "        def meanMapping(inputColumn, mean_dict):\n",
    "            outputLS = []\n",
    "            for idx, sch_id in enumerate(inputColumn.values):\n",
    "                outputLS.append(mean_dict[sch_id])\n",
    "\n",
    "            return outputLS\n",
    "        \n",
    "\n",
    "        def matching(inputData, codeBook):\n",
    "            output = copy.deepcopy(inputData)\n",
    "            shouldBeCal = self.cb[self.cb['file name'] == 'should be caculated']\n",
    "            assert len(shouldBeCal) == 2, print('Error: check self.cb')\n",
    "            for national in output.keys():\n",
    "                beforeShape = output[national].shape[1]\n",
    "                \n",
    "                calVal = list(codeBook[codeBook['categories'] == 'resilient status']['NAME'])\n",
    "                calVal.remove('ESCS')\n",
    "                \n",
    "                for variable in shouldBeCal['NAME'].values:\n",
    "                \n",
    "                    if variable == 'AVG_S_TEST':    \n",
    "                        mean_dict = schoolMean(output[national], calVal)\n",
    "                        \n",
    "                    elif variable == 'AVG_S_ESCS':\n",
    "                        mean_dict = schoolMean(output[national], ['ESCS'])\n",
    "\n",
    "                    #평균 dict 활용해서 매칭 진행\n",
    "                    outputLS = meanMapping(output[national]['CNTSCHID'], mean_dict)\n",
    "                    assert len(outputLS) == output[national].shape[0], print('Error: ', len(outputLS))\n",
    "                    output[national][variable] = outputLS # 학교 데이터이므로, 학교에 맞춰서 추가하기\n",
    "\n",
    "                afterShape = output[national].shape[1]\n",
    "                assert afterShape - beforeShape == 2, print('Beofre: ', beforeShape, ' ... ', 'After: ', afterShape)\n",
    "            \n",
    "            return output\n",
    "\n",
    "        self._5_shouldBeCal['full'] = matching(self._4_ESCS['full'], codeBook = self.cb)\n",
    "        self._5_shouldBeCal['sliced'] = matching(self._4_ESCS['sliced'], codeBook = self.cb)\n",
    "\n",
    "    \n",
    "    def AdjustMinor(self):\n",
    "    # ```\n",
    "    # 마이너한 것들을 조정하기 위함\n",
    "    # ```\n",
    "        print('\\n\\n>>>> 7. Manually adjust')\n",
    "        # 두 데이터를 나라 row를 만들고, 합치기 위함\n",
    "        def Merge(inputData):\n",
    "            output = pd.concat([inputData['SK'], inputData['US']], axis=0)\n",
    "            assert inputData['SK'].shape[0] + inputData['US'].shape[0] == output.shape[0]\n",
    "\n",
    "            dropAcademic = ['CNTRYID', 'AcademicScore']\n",
    "            for column in output.columns:\n",
    "                if 'PV' in column:\n",
    "                    dropAcademic.append(column)\n",
    "\n",
    "            output.drop(dropAcademic, axis=1, inplace=True)\n",
    "            # print('>> columns: ', output.columns)\n",
    "            return output\n",
    "\n",
    "        # spss 편하도록, 주요 변수들을 앞으로 빼는 작업\n",
    "        def columnOrder(inputData,\n",
    "                        important_columns=['resilient']):\n",
    "            column_ID = ['CNT', 'CNTSCHID', 'CNTSTUID']\n",
    "            # try1\n",
    "            # inputData.set_index(important_columns, inplace=True)\n",
    "            # print('1. ', inputData.columns)\n",
    "\n",
    "            # idxDf = inputData.pop(column_ID)\n",
    "            # inputData.reset_index(inplace=True)\n",
    "            # output = inputData.insert(0, idxDf.name, idxDf)\n",
    "            # print('2. ', output.columns) \n",
    "\n",
    "\n",
    "            inputData.set_index(column_ID+important_columns, inplace=True)\n",
    "            inputData.reset_index(inplace=True)\n",
    "\n",
    "            return inputData\n",
    "\n",
    "        self.finalRS['full'] = Merge(self._5_shouldBeCal['full'])\n",
    "        self.finalRS['sliced'] = Merge(self._5_shouldBeCal['sliced'])\n",
    "\n",
    "        self.finalRS['full'] = columnOrder(self.finalRS['full'])\n",
    "        self.finalRS['sliced'] = columnOrder(self.finalRS['sliced'])\n",
    "\n",
    "\n",
    "processor = Preprocessing(LoadedData=loadedData, codeBook=Loader.cb, dummyCodeBook='dummyCoding.json')\n",
    "processor.noDataColumn()\n",
    "processor.Dummy(doDummy=False) # 굳이 dummy할 필요가 없음, rf에서 categorical / numerical 인식해야함\n",
    "processor.Join()\n",
    "processor.DropStudent()\n",
    "processor.ESCS(test_key='read_10')\n",
    "processor.shouldBeCalculated()\n",
    "processor.AdjustMinor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.ExcelWriter(os.path.join(BASE_DIR, 'data', 'preprocessing.xlsx')) as writer:\n",
    "    processor.finalRS['full'].to_excel(writer, sheet_name='full', index=False)\n",
    "    processor.finalRS['sliced'].to_excel(writer, sheet_name='sliced', index=False)\n",
    "\n",
    "with pd.ExcelWriter(os.path.join(BASE_DIR, 'data', 'raw_forValidate.xlsx')) as writer:\n",
    "    processor._3_dropNa['SK'].to_excel(writer, sheet_name='south korea', index=False)\n",
    "    processor._3_dropNa['US'].to_excel(writer, sheet_name='us', index=False)\n",
    "    processor._4_ESCS['sliced']['SK'].to_excel(writer, sheet_name='sliced', index=False)\n",
    "\n",
    "with pd.ExcelWriter(os.path.join(BASE_DIR, 'data', 'descriptive(raw).xlsx')) as writer:\n",
    "    processor.rs_1_columnFull.to_excel(writer, sheet_name='dsec_full', index=True)\n",
    "    processor.rs_1_columnSK.to_excel(writer, sheet_name='dsec_SK', index=True)\n",
    "    processor.rs_1_columnUS.to_excel(writer, sheet_name='dsec_US', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Descriptive Statics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 앞선 처리 데이터 불러오기\n",
    "fullData = pd.read_excel(os.path.join(BASE_DIR, 'data', 'preprocessing.xlsx'), sheet_name='full')\n",
    "# slicedData = pd.read_excel(os.path.join(BASE_DIR, 'data', 'preprocessing.xlsx'), sheet_name='sliced')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Descriptive:\n",
    "    def __init__(self, cleanedData):\n",
    "        self.df = cleanedData\n",
    "        self.NUM = {'full': pd.DataFrame(),\n",
    "                    'SK': {'SK': pd.DataFrame(), 'res': pd.DataFrame(), 'nonRes': pd.DataFrame()},\n",
    "                    'US': {'SK': pd.DataFrame(), 'res': pd.DataFrame(), 'nonRes': pd.DataFrame()}\n",
    "                    }\n",
    "        self.CAT = {'full': pd.DataFrame(),\n",
    "                    'SK': {'SK': pd.DataFrame(), 'res': pd.DataFrame(), 'nonRes': pd.DataFrame()},\n",
    "                    'US': {'SK': pd.DataFrame(), 'res': pd.DataFrame(), 'nonRes': pd.DataFrame()}\n",
    "                    }\n",
    "\n",
    "        self._1_full = pd.DataFrame()\n",
    "        self._2_SKFull = pd.DataFrame()\n",
    "        self._2_SKRes = pd.DataFrame()\n",
    "        self._2_SKnonRes = pd.DataFrame()\n",
    "        self._3_US = pd.DataFrame()\n",
    "        self._3_USRes = pd.DataFrame()\n",
    "        self._3_USnonRes = pd.DataFrame()\n",
    "        \n",
    "    def Numeric(self):\n",
    "\n",
    "        def naRatio(fullCount, inputArr):\n",
    "            output = 100 - inputArr/fullCount*100\n",
    "            return np.round(output, decimals=2)\n",
    "\n",
    "        def Full(inputData):\n",
    "            output = inputData.describe().T.round(2)\n",
    "            output['na_ratio'] = naRatio(inputData.shape[0], output['count'])\n",
    "            return output\n",
    "\n",
    "        def groupBy(inputData, groupByColumn):\n",
    "            output= {}\n",
    "            \n",
    "            for uniqueVal in inputData[groupByColumn].unique():\n",
    "                str_uniqueVal = str(uniqueVal) # in case of resilient, type changed\n",
    "                # print(str_uniqueVal)\n",
    "                df_slice = inputData[inputData[groupByColumn] == uniqueVal]\n",
    "                output[str_uniqueVal]= df_slice.describe().T.round(2)\n",
    "                output[str_uniqueVal]['na_ratio'] = naRatio(df_slice.shape[0], output[str_uniqueVal]['count'])\n",
    "                \n",
    "            return output\n",
    "\n",
    "        self.NUM['full'] = Full(self.df)\n",
    "\n",
    "        nationDict = groupBy(self.df, groupByColumn='CNT')\n",
    "        self.NUM['SK']['SK'] = nationDict['Korea']\n",
    "        self.NUM['US']['US'] = nationDict['United States']\n",
    "\n",
    "        resilientSK = groupBy(self.df[self.df['CNT'] == 'Korea'], groupByColumn='resilient')\n",
    "        self.NUM['SK']['res'] = resilientSK['1']\n",
    "        self.NUM['SK']['nonRes'] = resilientSK['0']\n",
    "        \n",
    "        resilientUS = groupBy(self.df[self.df['CNT'] == 'United States'], groupByColumn='resilient')\n",
    "        self.NUM['US']['res'] = resilientUS['1']\n",
    "        self.NUM['US']['nonRes'] = resilientUS['0']\n",
    "\n",
    "\n",
    "    def Categorical(self):\n",
    "\n",
    "        def sliceCategorical(inputData,\n",
    "                            referenceNumerical # for assert \n",
    "                            ):   \n",
    "            num_cols = inputData._get_numeric_data().columns\n",
    "            cat_cols = list(set(inputData.columns) - set(num_cols))\n",
    "            \n",
    "            assert list(num_cols) == list(referenceNumerical.index), print(num_cols)\n",
    "\n",
    "            return cat_cols\n",
    "\n",
    "        def Full(inputData, cat_cols):\n",
    "            df_cat = inputData[cat_cols]\n",
    "            temp = df_cat.describe(include='all').T\n",
    "            temp['na_ratio'] = temp['freq'].values/temp['count'].values*100\n",
    "            # temp['na_ratio'] = np.round(temp['na_ratio'], 2) #!# error: infinite\n",
    "            return temp\n",
    "            \n",
    "\n",
    "        def groupBy(inputData, groupByColumn, cat_cols):\n",
    "            output= {}\n",
    "            for uniqueVal in inputData[groupByColumn].unique():\n",
    "                str_uniqueVal = str(uniqueVal) # in case of resilient, type changed\n",
    "                df_slice = inputData[inputData[groupByColumn] == uniqueVal]\n",
    "                df_cat = df_slice[cat_cols] # slice\n",
    "                temp = df_cat.describe(include='all').T\n",
    "                \n",
    "                temp['na_ratio'] = 100 - temp['freq'].values/temp['count'].values*100\n",
    "                # temp['na_ratio'] = np.round(temp['na_ratio'], 2) #!# error: infinite\n",
    "                output[str_uniqueVal] = temp.round(2)\n",
    "                \n",
    "            return output\n",
    "\n",
    "        \n",
    "        cat_cols = sliceCategorical(self.df, referenceNumerical=self.NUM['full'])\n",
    "        self.CAT['full'] = Full(self.df, cat_cols=cat_cols)\n",
    "        \n",
    "        nationDict = groupBy(self.df, groupByColumn='CNT', cat_cols=cat_cols)\n",
    "        self.CAT['SK']['SK'] = nationDict['Korea']\n",
    "        self.CAT['US']['US'] = nationDict['United States']\n",
    "\n",
    "\n",
    "        resilientSK = groupBy(self.df[self.df['CNT'] == 'Korea'], groupByColumn='resilient', cat_cols=cat_cols)\n",
    "        self.CAT['SK']['res'] = resilientSK['1']\n",
    "        self.CAT['SK']['nonRes'] = resilientSK['0']\n",
    "        \n",
    "        resilientUS = groupBy(self.df[self.df['CNT'] == 'United States'], groupByColumn='resilient', cat_cols=cat_cols)\n",
    "        self.CAT['US']['res'] = resilientUS['1']\n",
    "        self.CAT['US']['nonRes'] = resilientUS['0']\n",
    "        \n",
    "    \n",
    "    def Join(self):\n",
    "\n",
    "        def merger(df_num, df_cat):\n",
    "            output = pd.concat([df_num, df_cat], axis=0) # concate on row\n",
    "            # for cat_idx in df_cat.index:\n",
    "            # 합치면 좋겠지만, num, cat 구분 잘되서 좋음\n",
    "\n",
    "            ## drop unnecessary columns\n",
    "            output.drop(columns=['min', '25%', '50%', '75%', 'max'], inplace=True)\n",
    "            output.drop(index=['CNTSCHID', 'CNTSTUID', 'CNT', 'resilient'], inplace=True)\n",
    "\n",
    "            ## re-order columns \n",
    "            output.reset_index(drop=False, inplace=True)\n",
    "            output.set_index(['index', 'count', 'na_ratio'], inplace=True)\n",
    "            output.reset_index(drop=False, inplace=True)\n",
    "            output.set_index('index',inplace=True)\n",
    "            return output.round(2)\n",
    "        \n",
    "        self._1_full = merger(self.NUM['full'], self.CAT['full'])\n",
    "        self._2_SKFull = merger(self.NUM['SK']['SK'], self.CAT['SK']['SK'])\n",
    "        self._2_SKRes = merger(self.NUM['SK']['res'], self.CAT['SK']['res'])\n",
    "        self._2_SKnonRes = merger(self.NUM['SK']['nonRes'], self.CAT['SK']['nonRes'])\n",
    "        self._3_USFull = merger(self.NUM['US']['US'], self.CAT['US']['US'])\n",
    "        self._3_USRes = merger(self.NUM['US']['res'], self.CAT['US']['res'])\n",
    "        self._3_USnonRes = merger(self.NUM['US']['nonRes'], self.CAT['US']['nonRes'])\n",
    "        \n",
    "        \n",
    "\n",
    "analyzer = Descriptive(fullData)\n",
    "analyzer.Numeric()\n",
    "analyzer.Categorical()\n",
    "analyzer.Join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.ExcelWriter(os.path.join(BASE_DIR, 'data', 'descriptive(cleaned).xlsx')) as writer:\n",
    "    analyzer._1_full.to_excel(writer, sheet_name='full', index=True)\n",
    "    analyzer._2_SKFull.to_excel(writer, sheet_name='Korea_f', index=True)\n",
    "    analyzer._2_SKRes.to_excel(writer, sheet_name='Korea_r', index=True)\n",
    "    analyzer._2_SKnonRes.to_excel(writer, sheet_name='Korea_nR', index=True)\n",
    "    analyzer._3_USFull.to_excel(writer, sheet_name='US_f', index=True)\n",
    "    analyzer._3_USRes.to_excel(writer, sheet_name='US_r', index=True)\n",
    "    analyzer._3_USnonRes.to_excel(writer, sheet_name='US_nR', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest\n",
    "- just for comparing results of random forest btw python and r"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('khrrc')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f2ed4711497f95c801e11ec0b21dd929a4a0de8689951f49fbf9abba32131afd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
